{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7084663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üöÄ EVALUACI√ìN COMPLETA DEL DATASET MVTEC AD\n",
      "================================================================================\n",
      "üîç Encontradas 15 categor√≠as en /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw\n",
      "\n",
      "================================================================================\n",
      "üöÄ EVALUACI√ìN COMPLETA DEL DATASET MVTEC AD\n",
      "================================================================================\n",
      "   Modelo: /home/bllancao/Portafolio/mvtec_anomaly_detection/models/dinov2-base\n",
      "   Capa: -1\n",
      "   k-NN: k=1\n",
      "   Umbral: 0.6\n",
      "   Categor√≠as: 15\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìÇ [1/15] Categor√≠a: BOTTLE\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'bottle'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/bottle/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 3 tipos de anomal√≠a en 'bottle'\n",
      "Cargados 20 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/bottle/test/broken_large\n",
      "\n",
      "  üìç Tipo: broken_large (20 im√°genes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2951/3687707856.py:902: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  au_pro = np.trapz(pro_sorted, fpr_sorted) / fpr_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     IoU: 0.6007 | Dice: 0.7490 | F1: 0.7490 | AU-PRO: 0.8788\n",
      "Cargados 22 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/bottle/test/broken_small\n",
      "\n",
      "  üìç Tipo: broken_small (22 im√°genes)\n",
      "     IoU: 0.5307 | Dice: 0.6900 | F1: 0.6900 | AU-PRO: 0.8707\n",
      "Cargados 21 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/bottle/test/contamination\n",
      "\n",
      "  üìç Tipo: contamination (21 im√°genes)\n",
      "     IoU: 0.5631 | Dice: 0.6936 | F1: 0.6936 | AU-PRO: 0.9250\n",
      "\n",
      "================================================================================\n",
      "üìÇ [2/15] Categor√≠a: CABLE\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'cable'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 8 tipos de anomal√≠a en 'cable'\n",
      "Cargados 13 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/bent_wire\n",
      "\n",
      "  üìç Tipo: bent_wire (13 im√°genes)\n",
      "     IoU: 0.3629 | Dice: 0.5244 | F1: 0.5244 | AU-PRO: 0.8830\n",
      "Cargados 12 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/cable_swap\n",
      "\n",
      "  üìç Tipo: cable_swap (12 im√°genes)\n",
      "     IoU: 0.0935 | Dice: 0.1691 | F1: 0.1691 | AU-PRO: 0.2837\n",
      "Cargados 11 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/combined\n",
      "\n",
      "  üìç Tipo: combined (11 im√°genes)\n",
      "     IoU: 0.2698 | Dice: 0.4201 | F1: 0.4201 | AU-PRO: 0.6239\n",
      "Cargados 14 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/cut_inner_insulation\n",
      "\n",
      "  üìç Tipo: cut_inner_insulation (14 im√°genes)\n",
      "     IoU: 0.3514 | Dice: 0.5103 | F1: 0.5103 | AU-PRO: 0.8511\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/cut_outer_insulation\n",
      "\n",
      "  üìç Tipo: cut_outer_insulation (10 im√°genes)\n",
      "     IoU: 0.1847 | Dice: 0.3054 | F1: 0.3054 | AU-PRO: 0.7622\n",
      "Cargados 12 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/missing_cable\n",
      "\n",
      "  üìç Tipo: missing_cable (12 im√°genes)\n",
      "     IoU: 0.5423 | Dice: 0.7007 | F1: 0.7007 | AU-PRO: 0.8528\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/missing_wire\n",
      "\n",
      "  üìç Tipo: missing_wire (10 im√°genes)\n",
      "     IoU: 0.2580 | Dice: 0.3926 | F1: 0.3926 | AU-PRO: 0.9162\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/cable/test/poke_insulation\n",
      "\n",
      "  üìç Tipo: poke_insulation (10 im√°genes)\n",
      "     IoU: 0.3312 | Dice: 0.4708 | F1: 0.4708 | AU-PRO: 0.8294\n",
      "\n",
      "================================================================================\n",
      "üìÇ [3/15] Categor√≠a: CAPSULE\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'capsule'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/capsule/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'capsule'\n",
      "Cargados 23 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/capsule/test/crack\n",
      "\n",
      "  üìç Tipo: crack (23 im√°genes)\n",
      "     IoU: 0.1640 | Dice: 0.2624 | F1: 0.2624 | AU-PRO: 0.8822\n",
      "Cargados 22 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/capsule/test/faulty_imprint\n",
      "\n",
      "  üìç Tipo: faulty_imprint (22 im√°genes)\n",
      "     IoU: 0.1981 | Dice: 0.3119 | F1: 0.3119 | AU-PRO: 0.8947\n",
      "Cargados 21 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/capsule/test/poke\n",
      "\n",
      "  üìç Tipo: poke (21 im√°genes)\n",
      "     IoU: 0.1335 | Dice: 0.2252 | F1: 0.2252 | AU-PRO: 0.9019\n",
      "Cargados 23 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/capsule/test/scratch\n",
      "\n",
      "  üìç Tipo: scratch (23 im√°genes)\n",
      "     IoU: 0.2312 | Dice: 0.3555 | F1: 0.3555 | AU-PRO: 0.8740\n",
      "Cargados 20 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/capsule/test/squeeze\n",
      "\n",
      "  üìç Tipo: squeeze (20 im√°genes)\n",
      "     IoU: 0.2823 | Dice: 0.4205 | F1: 0.4205 | AU-PRO: 0.8291\n",
      "\n",
      "================================================================================\n",
      "üìÇ [4/15] Categor√≠a: CARPET\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'carpet'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/carpet/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'carpet'\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/carpet/test/color\n",
      "\n",
      "  üìç Tipo: color (19 im√°genes)\n",
      "     IoU: 0.2919 | Dice: 0.4420 | F1: 0.4420 | AU-PRO: 0.8966\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/carpet/test/cut\n",
      "\n",
      "  üìç Tipo: cut (17 im√°genes)\n",
      "     IoU: 0.4992 | Dice: 0.6603 | F1: 0.6603 | AU-PRO: 0.9152\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/carpet/test/hole\n",
      "\n",
      "  üìç Tipo: hole (17 im√°genes)\n",
      "     IoU: 0.3308 | Dice: 0.4912 | F1: 0.4912 | AU-PRO: 0.9349\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/carpet/test/metal_contamination\n",
      "\n",
      "  üìç Tipo: metal_contamination (17 im√°genes)\n",
      "     IoU: 0.1108 | Dice: 0.1983 | F1: 0.1983 | AU-PRO: 0.8915\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/carpet/test/thread\n",
      "\n",
      "  üìç Tipo: thread (19 im√°genes)\n",
      "     IoU: 0.1327 | Dice: 0.2265 | F1: 0.2265 | AU-PRO: 0.8240\n",
      "\n",
      "================================================================================\n",
      "üìÇ [5/15] Categor√≠a: GRID\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'grid'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/grid/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'grid'\n",
      "Cargados 12 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/grid/test/bent\n",
      "\n",
      "  üìç Tipo: bent (12 im√°genes)\n",
      "     IoU: 0.1493 | Dice: 0.2540 | F1: 0.2540 | AU-PRO: 0.8561\n",
      "Cargados 12 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/grid/test/broken\n",
      "\n",
      "  üìç Tipo: broken (12 im√°genes)\n",
      "     IoU: 0.0925 | Dice: 0.1651 | F1: 0.1651 | AU-PRO: 0.8312\n",
      "Cargados 11 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/grid/test/glue\n",
      "\n",
      "  üìç Tipo: glue (11 im√°genes)\n",
      "     IoU: 0.1673 | Dice: 0.2797 | F1: 0.2797 | AU-PRO: 0.8576\n",
      "Cargados 11 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/grid/test/metal_contamination\n",
      "\n",
      "  üìç Tipo: metal_contamination (11 im√°genes)\n",
      "     IoU: 0.1063 | Dice: 0.1911 | F1: 0.1911 | AU-PRO: 0.8747\n",
      "Cargados 11 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/grid/test/thread\n",
      "\n",
      "  üìç Tipo: thread (11 im√°genes)\n",
      "     IoU: 0.1751 | Dice: 0.2935 | F1: 0.2935 | AU-PRO: 0.8385\n",
      "\n",
      "================================================================================\n",
      "üìÇ [6/15] Categor√≠a: HAZELNUT\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'hazelnut'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/hazelnut/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 4 tipos de anomal√≠a en 'hazelnut'\n",
      "Cargados 18 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/hazelnut/test/crack\n",
      "\n",
      "  üìç Tipo: crack (18 im√°genes)\n",
      "     IoU: 0.4368 | Dice: 0.5757 | F1: 0.5757 | AU-PRO: 0.8996\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/hazelnut/test/cut\n",
      "\n",
      "  üìç Tipo: cut (17 im√°genes)\n",
      "     IoU: 0.1678 | Dice: 0.2847 | F1: 0.2847 | AU-PRO: 0.9158\n",
      "Cargados 18 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/hazelnut/test/hole\n",
      "\n",
      "  üìç Tipo: hole (18 im√°genes)\n",
      "     IoU: 0.2942 | Dice: 0.4443 | F1: 0.4443 | AU-PRO: 0.8850\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/hazelnut/test/print\n",
      "\n",
      "  üìç Tipo: print (17 im√°genes)\n",
      "     IoU: 0.4418 | Dice: 0.6063 | F1: 0.6063 | AU-PRO: 0.9001\n",
      "\n",
      "================================================================================\n",
      "üìÇ [7/15] Categor√≠a: LEATHER\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'leather'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/leather/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'leather'\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/leather/test/color\n",
      "\n",
      "  üìç Tipo: color (19 im√°genes)\n",
      "     IoU: 0.0866 | Dice: 0.1567 | F1: 0.1567 | AU-PRO: 0.9180\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/leather/test/cut\n",
      "\n",
      "  üìç Tipo: cut (19 im√°genes)\n",
      "     IoU: 0.0642 | Dice: 0.1181 | F1: 0.1181 | AU-PRO: 0.9479\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/leather/test/fold\n",
      "\n",
      "  üìç Tipo: fold (17 im√°genes)\n",
      "     IoU: 0.2431 | Dice: 0.3799 | F1: 0.3799 | AU-PRO: 0.9400\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/leather/test/glue\n",
      "\n",
      "  üìç Tipo: glue (19 im√°genes)\n",
      "     IoU: 0.1289 | Dice: 0.2240 | F1: 0.2240 | AU-PRO: 0.9138\n",
      "Cargados 18 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/leather/test/poke\n",
      "\n",
      "  üìç Tipo: poke (18 im√°genes)\n",
      "     IoU: 0.0381 | Dice: 0.0727 | F1: 0.0727 | AU-PRO: 0.9455\n",
      "\n",
      "================================================================================\n",
      "üìÇ [8/15] Categor√≠a: METAL_NUT\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'metal_nut'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/metal_nut/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 4 tipos de anomal√≠a en 'metal_nut'\n",
      "Cargados 25 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/metal_nut/test/bent\n",
      "\n",
      "  üìç Tipo: bent (25 im√°genes)\n",
      "     IoU: 0.2062 | Dice: 0.3320 | F1: 0.3320 | AU-PRO: 0.8234\n",
      "Cargados 22 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/metal_nut/test/color\n",
      "\n",
      "  üìç Tipo: color (22 im√°genes)\n",
      "     IoU: 0.3675 | Dice: 0.5207 | F1: 0.5207 | AU-PRO: 0.8361\n",
      "Cargados 23 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/metal_nut/test/flip\n",
      "\n",
      "  üìç Tipo: flip (23 im√°genes)\n",
      "     IoU: 0.5491 | Dice: 0.7045 | F1: 0.7045 | AU-PRO: 0.7248\n",
      "Cargados 23 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/metal_nut/test/scratch\n",
      "\n",
      "  üìç Tipo: scratch (23 im√°genes)\n",
      "     IoU: 0.4220 | Dice: 0.5809 | F1: 0.5809 | AU-PRO: 0.8102\n",
      "\n",
      "================================================================================\n",
      "üìÇ [9/15] Categor√≠a: PILL\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'pill'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 7 tipos de anomal√≠a en 'pill'\n",
      "Cargados 25 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/color\n",
      "\n",
      "  üìç Tipo: color (25 im√°genes)\n",
      "     IoU: 0.1040 | Dice: 0.1796 | F1: 0.1796 | AU-PRO: 0.8920\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/combined\n",
      "\n",
      "  üìç Tipo: combined (17 im√°genes)\n",
      "     IoU: 0.2863 | Dice: 0.4302 | F1: 0.4302 | AU-PRO: 0.7974\n",
      "Cargados 21 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/contamination\n",
      "\n",
      "  üìç Tipo: contamination (21 im√°genes)\n",
      "     IoU: 0.3511 | Dice: 0.5022 | F1: 0.5022 | AU-PRO: 0.8723\n",
      "Cargados 26 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/crack\n",
      "\n",
      "  üìç Tipo: crack (26 im√°genes)\n",
      "     IoU: 0.2301 | Dice: 0.3598 | F1: 0.3598 | AU-PRO: 0.9127\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/faulty_imprint\n",
      "\n",
      "  üìç Tipo: faulty_imprint (19 im√°genes)\n",
      "     IoU: 0.4066 | Dice: 0.5558 | F1: 0.5558 | AU-PRO: 0.8900\n",
      "Cargados 9 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/pill_type\n",
      "\n",
      "  üìç Tipo: pill_type (9 im√°genes)\n",
      "     IoU: 0.3694 | Dice: 0.5258 | F1: 0.5258 | AU-PRO: 0.8192\n",
      "Cargados 24 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/pill/test/scratch\n",
      "\n",
      "  üìç Tipo: scratch (24 im√°genes)\n",
      "     IoU: 0.3942 | Dice: 0.5435 | F1: 0.5435 | AU-PRO: 0.8971\n",
      "\n",
      "================================================================================\n",
      "üìÇ [10/15] Categor√≠a: SCREW\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'screw'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/screw/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'screw'\n",
      "Cargados 24 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/screw/test/manipulated_front\n",
      "\n",
      "  üìç Tipo: manipulated_front (24 im√°genes)\n",
      "     IoU: 0.0559 | Dice: 0.1010 | F1: 0.1010 | AU-PRO: 0.6371\n",
      "Cargados 24 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/screw/test/scratch_head\n",
      "\n",
      "  üìç Tipo: scratch_head (24 im√°genes)\n",
      "     IoU: 0.0427 | Dice: 0.0789 | F1: 0.0789 | AU-PRO: 0.7900\n",
      "Cargados 25 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/screw/test/scratch_neck\n",
      "\n",
      "  üìç Tipo: scratch_neck (25 im√°genes)\n",
      "     IoU: 0.1747 | Dice: 0.2888 | F1: 0.2888 | AU-PRO: 0.9216\n",
      "Cargados 23 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/screw/test/thread_side\n",
      "\n",
      "  üìç Tipo: thread_side (23 im√°genes)\n",
      "     IoU: 0.0229 | Dice: 0.0427 | F1: 0.0427 | AU-PRO: 0.3421\n",
      "Cargados 23 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/screw/test/thread_top\n",
      "\n",
      "  üìç Tipo: thread_top (23 im√°genes)\n",
      "     IoU: 0.1559 | Dice: 0.2423 | F1: 0.2423 | AU-PRO: 0.6626\n",
      "\n",
      "================================================================================\n",
      "üìÇ [11/15] Categor√≠a: TILE\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'tile'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/tile/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'tile'\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/tile/test/crack\n",
      "\n",
      "  üìç Tipo: crack (17 im√°genes)\n",
      "     IoU: 0.1144 | Dice: 0.2029 | F1: 0.2029 | AU-PRO: 0.8388\n",
      "Cargados 18 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/tile/test/glue_strip\n",
      "\n",
      "  üìç Tipo: glue_strip (18 im√°genes)\n",
      "     IoU: 0.4393 | Dice: 0.6031 | F1: 0.6031 | AU-PRO: 0.7884\n",
      "Cargados 16 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/tile/test/gray_stroke\n",
      "\n",
      "  üìç Tipo: gray_stroke (16 im√°genes)\n",
      "     IoU: 0.4243 | Dice: 0.5872 | F1: 0.5872 | AU-PRO: 0.9093\n",
      "Cargados 18 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/tile/test/oil\n",
      "\n",
      "  üìç Tipo: oil (18 im√°genes)\n",
      "     IoU: 0.5843 | Dice: 0.7343 | F1: 0.7343 | AU-PRO: 0.8341\n",
      "Cargados 15 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/tile/test/rough\n",
      "\n",
      "  üìç Tipo: rough (15 im√°genes)\n",
      "     IoU: 0.7628 | Dice: 0.8610 | F1: 0.8610 | AU-PRO: 0.8939\n",
      "\n",
      "================================================================================\n",
      "üìÇ [12/15] Categor√≠a: TOOTHBRUSH\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'toothbrush'...\n",
      "Cargadas 60 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/toothbrush/train/good\n",
      "Procesadas 10/60 im√°genes\n",
      "Procesadas 20/60 im√°genes\n",
      "Procesadas 30/60 im√°genes\n",
      "Procesadas 40/60 im√°genes\n",
      "Procesadas 50/60 im√°genes\n",
      "Procesadas 60/60 im√°genes\n",
      "Memory Bank construido: 15360 patches, dim=768\n",
      "\n",
      "üîç Evaluando 1 tipos de anomal√≠a en 'toothbrush'\n",
      "Cargados 30 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/toothbrush/test/defective\n",
      "\n",
      "  üìç Tipo: defective (30 im√°genes)\n",
      "     IoU: 0.2145 | Dice: 0.3332 | F1: 0.3332 | AU-PRO: 0.8669\n",
      "\n",
      "================================================================================\n",
      "üìÇ [13/15] Categor√≠a: TRANSISTOR\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'transistor'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/transistor/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 4 tipos de anomal√≠a en 'transistor'\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/transistor/test/bent_lead\n",
      "\n",
      "  üìç Tipo: bent_lead (10 im√°genes)\n",
      "     IoU: 0.1263 | Dice: 0.2194 | F1: 0.2194 | AU-PRO: 0.8316\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/transistor/test/cut_lead\n",
      "\n",
      "  üìç Tipo: cut_lead (10 im√°genes)\n",
      "     IoU: 0.2521 | Dice: 0.3918 | F1: 0.3918 | AU-PRO: 0.7958\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/transistor/test/damaged_case\n",
      "\n",
      "  üìç Tipo: damaged_case (10 im√°genes)\n",
      "     IoU: 0.5451 | Dice: 0.6929 | F1: 0.6929 | AU-PRO: 0.8635\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/transistor/test/misplaced\n",
      "\n",
      "  üìç Tipo: misplaced (10 im√°genes)\n",
      "     IoU: 0.2235 | Dice: 0.3382 | F1: 0.3382 | AU-PRO: 0.2735\n",
      "\n",
      "================================================================================\n",
      "üìÇ [14/15] Categor√≠a: WOOD\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'wood'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/wood/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 5 tipos de anomal√≠a en 'wood'\n",
      "Cargados 8 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/wood/test/color\n",
      "\n",
      "  üìç Tipo: color (8 im√°genes)\n",
      "     IoU: 0.3678 | Dice: 0.5146 | F1: 0.5146 | AU-PRO: 0.8764\n",
      "Cargados 11 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/wood/test/combined\n",
      "\n",
      "  üìç Tipo: combined (11 im√°genes)\n",
      "     IoU: 0.3426 | Dice: 0.4703 | F1: 0.4703 | AU-PRO: 0.7510\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/wood/test/hole\n",
      "\n",
      "  üìç Tipo: hole (10 im√°genes)\n",
      "     IoU: 0.1286 | Dice: 0.2172 | F1: 0.2172 | AU-PRO: 0.8333\n",
      "Cargados 10 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/wood/test/liquid\n",
      "\n",
      "  üìç Tipo: liquid (10 im√°genes)\n",
      "     IoU: 0.4800 | Dice: 0.6431 | F1: 0.6431 | AU-PRO: 0.8891\n",
      "Cargados 21 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/wood/test/scratch\n",
      "\n",
      "  üìç Tipo: scratch (21 im√°genes)\n",
      "     IoU: 0.3094 | Dice: 0.4438 | F1: 0.4438 | AU-PRO: 0.7441\n",
      "\n",
      "================================================================================\n",
      "üìÇ [15/15] Categor√≠a: ZIPPER\n",
      "================================================================================\n",
      "\n",
      "üì¶ Construyendo Memory Bank para 'zipper'...\n",
      "Cargadas 200 im√°genes de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/train/good\n",
      "Procesadas 10/200 im√°genes\n",
      "Procesadas 20/200 im√°genes\n",
      "Procesadas 30/200 im√°genes\n",
      "Procesadas 40/200 im√°genes\n",
      "Procesadas 50/200 im√°genes\n",
      "Procesadas 60/200 im√°genes\n",
      "Procesadas 70/200 im√°genes\n",
      "Procesadas 80/200 im√°genes\n",
      "Procesadas 90/200 im√°genes\n",
      "Procesadas 100/200 im√°genes\n",
      "Procesadas 110/200 im√°genes\n",
      "Procesadas 120/200 im√°genes\n",
      "Procesadas 130/200 im√°genes\n",
      "Procesadas 140/200 im√°genes\n",
      "Procesadas 150/200 im√°genes\n",
      "Procesadas 160/200 im√°genes\n",
      "Procesadas 170/200 im√°genes\n",
      "Procesadas 180/200 im√°genes\n",
      "Procesadas 190/200 im√°genes\n",
      "Procesadas 200/200 im√°genes\n",
      "Memory Bank construido: 51200 patches, dim=768\n",
      "\n",
      "üîç Evaluando 7 tipos de anomal√≠a en 'zipper'\n",
      "Cargados 19 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/broken_teeth\n",
      "\n",
      "  üìç Tipo: broken_teeth (19 im√°genes)\n",
      "     IoU: 0.3005 | Dice: 0.4439 | F1: 0.4439 | AU-PRO: 0.7564\n",
      "Cargados 16 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/combined\n",
      "\n",
      "  üìç Tipo: combined (16 im√°genes)\n",
      "     IoU: 0.2376 | Dice: 0.3707 | F1: 0.3707 | AU-PRO: 0.7673\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/fabric_border\n",
      "\n",
      "  üìç Tipo: fabric_border (17 im√°genes)\n",
      "     IoU: 0.2374 | Dice: 0.3791 | F1: 0.3791 | AU-PRO: 0.8457\n",
      "Cargados 16 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/fabric_interior\n",
      "\n",
      "  üìç Tipo: fabric_interior (16 im√°genes)\n",
      "     IoU: 0.2861 | Dice: 0.4348 | F1: 0.4348 | AU-PRO: 0.8185\n",
      "Cargados 17 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/rough\n",
      "\n",
      "  üìç Tipo: rough (17 im√°genes)\n",
      "     IoU: 0.3140 | Dice: 0.4581 | F1: 0.4581 | AU-PRO: 0.7348\n",
      "Cargados 18 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/split_teeth\n",
      "\n",
      "  üìç Tipo: split_teeth (18 im√°genes)\n",
      "     IoU: 0.2906 | Dice: 0.4329 | F1: 0.4329 | AU-PRO: 0.8608\n",
      "Cargados 16 pares (test, ground_truth) de /home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw/zipper/test/squeezed_teeth\n",
      "\n",
      "  üìç Tipo: squeezed_teeth (16 im√°genes)\n",
      "     IoU: 0.2924 | Dice: 0.4382 | F1: 0.4382 | AU-PRO: 0.8862\n",
      "\n",
      "================================================================================\n",
      "üìä RESUMEN FINAL DE EVALUACI√ìN\n",
      "================================================================================\n",
      "\n",
      "üè∑Ô∏è  M√âTRICAS POR CATEGOR√çA:\n",
      "--------------------------------------------------------------------------------\n",
      "Categor√≠a       IoU        Dice       F1         Precision  Recall     AU-PRO    \n",
      "--------------------------------------------------------------------------------\n",
      "bottle          0.5637     0.7099     0.7099     0.6339     0.8779     0.8913    \n",
      "cable           0.3041     0.4425     0.4425     0.3391     0.7909     0.7497    \n",
      "capsule         0.2009     0.3139     0.3139     0.2315     0.7832     0.8770    \n",
      "carpet          0.2703     0.4005     0.4005     0.2740     0.9670     0.8910    \n",
      "grid            0.1375     0.2357     0.2357     0.1407     0.8709     0.8513    \n",
      "hazelnut        0.3360     0.4787     0.4787     0.3445     0.9531     0.8999    \n",
      "leather         0.1102     0.1875     0.1875     0.1103     0.9977     0.9327    \n",
      "metal_nut       0.3825     0.5303     0.5303     0.5529     0.5986     0.7988    \n",
      "pill            0.2932     0.4258     0.4258     0.3691     0.7975     0.8774    \n",
      "screw           0.0912     0.1520     0.1520     0.0956     0.5556     0.6756    \n",
      "tile            0.4595     0.5932     0.5932     0.4945     0.9325     0.8503    \n",
      "toothbrush      0.2145     0.3332     0.3332     0.2299     0.8433     0.8669    \n",
      "transistor      0.2868     0.4106     0.4106     0.4057     0.5582     0.6911    \n",
      "wood            0.3216     0.4535     0.4535     0.3782     0.7693     0.8020    \n",
      "zipper          0.2804     0.4232     0.4232     0.3310     0.7268     0.8091    \n",
      "\n",
      "================================================================================\n",
      "üåç M√âTRICAS GLOBALES:\n",
      "================================================================================\n",
      "   Total im√°genes evaluadas: 1258\n",
      "   Total categor√≠as: 15\n",
      "\n",
      "   üìà M√©tricas Pixel-Level:\n",
      "      IoU:       0.2765 (¬± 0.1961)\n",
      "      Dice:      0.3981 (¬± 0.2318)\n",
      "      Precision: 0.3216 (¬± 0.2484)\n",
      "      Recall:    0.7953 (¬± 0.2501)\n",
      "      F1:        0.3981 (¬± 0.2318)\n",
      "\n",
      "   üìà M√©tricas Region-Level:\n",
      "      PRO:       0.7747 (¬± 0.2645)\n",
      "      AU-PRO:    0.8309 (¬± 0.1719)\n",
      "\n",
      "‚úÖ Evaluaci√≥n completa finalizada\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MVTec AD Anomaly Detection con DINOv2\n",
    "=====================================\n",
    "\n",
    "Dos m√©todos optimizados para MVTec AD (im√°genes alineadas):\n",
    "1. Dense Matching (Posicional) - Comparaci√≥n 1:1 entre patches\n",
    "2. Memory Bank + k-NN (PatchCore-style) - Estado del arte\n",
    "\n",
    "Ambos m√©todos permiten configurar la capa de extracci√≥n de features.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndimage\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import cv2\n",
    "import warnings\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCIONES DE NORMALIZACI√ìN Y RESIZE\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_anomaly_map(\n",
    "    anomaly_map: np.ndarray,\n",
    "    method: str = 'minmax',\n",
    "    clip_percentile: Optional[Tuple[float, float]] = None,\n",
    "    robust_percentile: Tuple[float, float] = (2, 98)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normaliza un mapa de anomal√≠a al rango [0, 1].\n",
    "    \n",
    "    Args:\n",
    "        anomaly_map: Mapa de anomal√≠a [H, W] con valores continuos\n",
    "        method: M√©todo de normalizaci√≥n:\n",
    "            - 'minmax': Normalizaci√≥n min-max est√°ndar\n",
    "            - 'robust': Normalizaci√≥n robusta usando percentiles (evita outliers)\n",
    "        clip_percentile: Tupla (min_percentile, max_percentile) para recortar\n",
    "                        valores extremos antes de normalizar. Ej: (1, 99)\n",
    "        robust_percentile: Percentiles a usar para normalizaci√≥n robusta.\n",
    "                          Por defecto (2, 98)\n",
    "    \n",
    "    Returns:\n",
    "        normalized_map: Mapa normalizado en [0, 1]\n",
    "    \n",
    "    Example:\n",
    "        >>> amap = normalize_anomaly_map(raw_scores, method='robust')\n",
    "        >>> amap = normalize_anomaly_map(raw_scores, clip_percentile=(1, 99))\n",
    "    \"\"\"\n",
    "    amap = anomaly_map.astype(np.float32).copy()\n",
    "    \n",
    "    # Paso 1: Recortar valores extremos si se especifica\n",
    "    if clip_percentile is not None:\n",
    "        p_min, p_max = clip_percentile\n",
    "        v_min = np.percentile(amap, p_min)\n",
    "        v_max = np.percentile(amap, p_max)\n",
    "        amap = np.clip(amap, v_min, v_max)\n",
    "    \n",
    "    # Paso 2: Normalizar seg√∫n el m√©todo\n",
    "    if method == 'minmax':\n",
    "        # Normalizaci√≥n min-max est√°ndar\n",
    "        amap_min = amap.min()\n",
    "        amap_max = amap.max()\n",
    "        \n",
    "        if amap_max > amap_min:\n",
    "            normalized = (amap - amap_min) / (amap_max - amap_min)\n",
    "        else:\n",
    "            # Mapa uniforme, retornar ceros\n",
    "            normalized = np.zeros_like(amap)\n",
    "            warnings.warn(\"Mapa de anomal√≠a tiene valores uniformes (min == max)\")\n",
    "    \n",
    "    elif method == 'robust':\n",
    "        # Normalizaci√≥n robusta usando percentiles\n",
    "        p_low, p_high = robust_percentile\n",
    "        v_low = np.percentile(amap, p_low)\n",
    "        v_high = np.percentile(amap, p_high)\n",
    "        \n",
    "        if v_high > v_low:\n",
    "            normalized = (amap - v_low) / (v_high - v_low)\n",
    "            normalized = np.clip(normalized, 0, 1)\n",
    "        else:\n",
    "            normalized = np.zeros_like(amap)\n",
    "            warnings.warn(\"Percentiles robustos iguales, usando normalizaci√≥n min-max\")\n",
    "            return normalize_anomaly_map(amap, method='minmax')\n",
    "    else:\n",
    "        raise ValueError(f\"M√©todo de normalizaci√≥n no v√°lido: {method}. Usar 'minmax' o 'robust'\")\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "\n",
    "def resize_anomaly_map(\n",
    "    anomaly_map: np.ndarray,\n",
    "    target_size: Tuple[int, int],\n",
    "    interpolation: str = 'bilinear'\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Redimensiona un mapa de anomal√≠a a un tama√±o objetivo.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_map: Mapa de anomal√≠a [H, W]\n",
    "        target_size: Tama√±o objetivo (height, width)\n",
    "        interpolation: M√©todo de interpolaci√≥n:\n",
    "            - 'bilinear': Interpolaci√≥n bilinear (suave, por defecto)\n",
    "            - 'nearest': Vecino m√°s cercano (preserva valores exactos)\n",
    "            - 'cubic': Interpolaci√≥n bic√∫bica (m√°s suave)\n",
    "    \n",
    "    Returns:\n",
    "        resized_map: Mapa redimensionado [target_H, target_W]\n",
    "    \"\"\"\n",
    "    interp_methods = {\n",
    "        'bilinear': cv2.INTER_LINEAR,\n",
    "        'nearest': cv2.INTER_NEAREST,\n",
    "        'cubic': cv2.INTER_CUBIC\n",
    "    }\n",
    "    \n",
    "    if interpolation not in interp_methods:\n",
    "        raise ValueError(f\"Interpolaci√≥n no v√°lida: {interpolation}. Usar: {list(interp_methods.keys())}\")\n",
    "    \n",
    "    # cv2.resize espera (width, height)\n",
    "    target_wh = (target_size[1], target_size[0])\n",
    "    \n",
    "    resized = cv2.resize(\n",
    "        anomaly_map.astype(np.float32),\n",
    "        target_wh,\n",
    "        interpolation=interp_methods[interpolation]\n",
    "    )\n",
    "    \n",
    "    return resized\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACI√ìN DEL MODELO\n",
    "# =============================================================================\n",
    "\n",
    "class DINOv2FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extractor de features con DINOv2 y capa configurable.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Ruta al modelo DINOv2\n",
    "        layer_idx: √çndice de la capa a usar (-1 = √∫ltima, 0 = embedding, etc.)\n",
    "        device: Dispositivo para inferencia ('cuda' o 'cpu')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, layer_idx: int = -1, device: str = None):\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "        self.model = AutoModel.from_pretrained(model_path).to(self.device)\n",
    "        self.model.eval()\n",
    "        self.layer_idx = layer_idx\n",
    "        \n",
    "        # DINOv2-base usa patches de 14x14\n",
    "        self.patch_size = 14\n",
    "        \n",
    "    def extract_patches(self, image: Image.Image, normalize: bool = True) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extrae embeddings de patches de una imagen.\n",
    "        \n",
    "        Args:\n",
    "            image: Imagen PIL\n",
    "            normalize: Si True, normaliza los embeddings (L2)\n",
    "            \n",
    "        Returns:\n",
    "            patches: Tensor [num_patches, hidden_dim]\n",
    "        \"\"\"\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\", do_rescale=True).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs, output_hidden_states=True)\n",
    "            \n",
    "            # Seleccionar capa espec√≠fica\n",
    "            if self.layer_idx == -1:\n",
    "                # √öltima capa (last_hidden_state)\n",
    "                hidden_states = outputs.last_hidden_state\n",
    "            else:\n",
    "                # Capa espec√≠fica de hidden_states\n",
    "                hidden_states = outputs.hidden_states[self.layer_idx]\n",
    "            \n",
    "            # Remover token CLS (primer token)\n",
    "            patches = hidden_states[:, 1:, :].squeeze(0)  # [num_patches, hidden_dim]\n",
    "            \n",
    "            if normalize:\n",
    "                patches = F.normalize(patches, p=2, dim=-1)\n",
    "                \n",
    "        return patches\n",
    "    \n",
    "    def extract_patches_batch(self, images: List[Image.Image], normalize: bool = True) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Extrae patches de m√∫ltiples im√°genes en batch.\n",
    "        \n",
    "        Returns:\n",
    "            patches: Tensor [batch, num_patches, hidden_dim]\n",
    "        \"\"\"\n",
    "        inputs = self.processor(images=images, return_tensors=\"pt\", do_rescale=True).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs, output_hidden_states=True)\n",
    "            \n",
    "            if self.layer_idx == -1:\n",
    "                hidden_states = outputs.last_hidden_state\n",
    "            else:\n",
    "                hidden_states = outputs.hidden_states[self.layer_idx]\n",
    "            \n",
    "            patches = hidden_states[:, 1:, :]  # [batch, num_patches, hidden_dim]\n",
    "            \n",
    "            if normalize:\n",
    "                patches = F.normalize(patches, p=2, dim=-1)\n",
    "                \n",
    "        return patches\n",
    "    \n",
    "    def get_grid_size(self, image: Image.Image) -> Tuple[int, int]:\n",
    "        \"\"\"Retorna el tama√±o del grid de patches (h, w).\"\"\"\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        h = inputs['pixel_values'].shape[-2] // self.patch_size\n",
    "        w = inputs['pixel_values'].shape[-1] // self.patch_size\n",
    "        return h, w\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# M√âTODO 1: DENSE MATCHING (POSICIONAL)\n",
    "# =============================================================================\n",
    "\n",
    "class DenseMatchingDetector:\n",
    "    \"\"\"\n",
    "    Detector de anomal√≠as por Dense Matching (correspondencia posicional 1:1).\n",
    "    \n",
    "    Ideal para MVTec AD donde las im√°genes est√°n bien alineadas.\n",
    "    Compara cada patch de la imagen test con el patch en la misma posici√≥n\n",
    "    de la imagen de referencia.\n",
    "    \n",
    "    Args:\n",
    "        extractor: Instancia de DINOv2FeatureExtractor\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, extractor: DINOv2FeatureExtractor):\n",
    "        self.extractor = extractor\n",
    "        \n",
    "    def compute_anomaly_map(\n",
    "        self, \n",
    "        test_image: Image.Image, \n",
    "        reference_image: Image.Image,\n",
    "        smooth_sigma: float = 0.8\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Calcula mapa de anomal√≠a por comparaci√≥n posicional 1:1.\n",
    "        \n",
    "        Args:\n",
    "            test_image: Imagen a evaluar\n",
    "            reference_image: Imagen de referencia (sin defectos)\n",
    "            smooth_sigma: Sigma para suavizado Gaussiano\n",
    "            \n",
    "        Returns:\n",
    "            anomaly_map: Mapa de anomal√≠a [H, W] sin suavizar\n",
    "            anomaly_map_smooth: Mapa de anomal√≠a [H, W] suavizado\n",
    "        \"\"\"\n",
    "        # Extraer patches de ambas im√°genes\n",
    "        test_patches = self.extractor.extract_patches(test_image)      # [N, D]\n",
    "        ref_patches = self.extractor.extract_patches(reference_image)  # [N, D]\n",
    "        \n",
    "        # Similitud coseno por patch (correspondencia posicional)\n",
    "        cosine_sim = (test_patches * ref_patches).sum(dim=-1)  # [N]\n",
    "        \n",
    "        # Anomal√≠a = 1 - similitud\n",
    "        anomaly_scores = (1 - cosine_sim).cpu().numpy()\n",
    "        \n",
    "        # Reshape a grid 2D\n",
    "        h, w = self.extractor.get_grid_size(test_image)\n",
    "        anomaly_map = anomaly_scores.reshape(h, w)\n",
    "        \n",
    "        # Suavizado\n",
    "        anomaly_map_smooth = ndimage.gaussian_filter(anomaly_map, sigma=smooth_sigma)\n",
    "        \n",
    "        return anomaly_map, anomaly_map_smooth\n",
    "    \n",
    "    def compute_anomaly_map_multi_ref(\n",
    "        self,\n",
    "        test_image: Image.Image,\n",
    "        reference_images: List[Image.Image],\n",
    "        aggregation: str = 'min',\n",
    "        smooth_sigma: float = 0.8\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Calcula mapa de anomal√≠a contra m√∫ltiples referencias.\n",
    "        \n",
    "        Args:\n",
    "            test_image: Imagen a evaluar\n",
    "            reference_images: Lista de im√°genes de referencia\n",
    "            aggregation: 'min' (menor distancia) o 'mean' (promedio)\n",
    "            smooth_sigma: Sigma para suavizado\n",
    "            \n",
    "        Returns:\n",
    "            anomaly_map, anomaly_map_smooth\n",
    "        \"\"\"\n",
    "        test_patches = self.extractor.extract_patches(test_image)  # [N, D]\n",
    "        \n",
    "        all_scores = []\n",
    "        for ref_img in reference_images:\n",
    "            ref_patches = self.extractor.extract_patches(ref_img)\n",
    "            cosine_sim = (test_patches * ref_patches).sum(dim=-1)\n",
    "            scores = 1 - cosine_sim\n",
    "            all_scores.append(scores)\n",
    "        \n",
    "        all_scores = torch.stack(all_scores, dim=0)  # [num_refs, N]\n",
    "        \n",
    "        if aggregation == 'min':\n",
    "            anomaly_scores = all_scores.min(dim=0)[0]\n",
    "        else:\n",
    "            anomaly_scores = all_scores.mean(dim=0)\n",
    "        \n",
    "        h, w = self.extractor.get_grid_size(test_image)\n",
    "        anomaly_map = anomaly_scores.cpu().numpy().reshape(h, w)\n",
    "        anomaly_map_smooth = ndimage.gaussian_filter(anomaly_map, sigma=smooth_sigma)\n",
    "        \n",
    "        return anomaly_map, anomaly_map_smooth\n",
    "    \n",
    "    def visualize(\n",
    "        self,\n",
    "        test_image: Image.Image,\n",
    "        reference_image: Image.Image,\n",
    "        anomaly_map: np.ndarray,\n",
    "        title: str = \"Dense Matching - Detecci√≥n de Anomal√≠as\"\n",
    "    ):\n",
    "        \"\"\"Visualiza resultado de detecci√≥n.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        axes[0].imshow(reference_image)\n",
    "        axes[0].set_title(\"Referencia (Sin defectos)\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(test_image)\n",
    "        axes[1].set_title(\"Imagen Test\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(test_image)\n",
    "        im = axes[2].imshow(\n",
    "            anomaly_map, \n",
    "            cmap='jet', \n",
    "            alpha=0.5, \n",
    "            extent=(0, test_image.width, test_image.height, 0)\n",
    "        )\n",
    "        axes[2].set_title(\"Mapa de Anomal√≠a\")\n",
    "        axes[2].axis('off')\n",
    "        plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.suptitle(title, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# M√âTODO 2: MEMORY BANK + k-NN (PATCHCORE-STYLE)\n",
    "# =============================================================================\n",
    "\n",
    "class MemoryBankDetector:\n",
    "    \"\"\"\n",
    "    Detector de anomal√≠as estilo PatchCore con Memory Bank + k-NN.\n",
    "    \n",
    "    Estado del arte para MVTec AD. Construye un banco de memoria con\n",
    "    patches de im√°genes normales y detecta anomal√≠as buscando patches\n",
    "    que no tienen vecinos cercanos en el banco.\n",
    "    \n",
    "    Args:\n",
    "        extractor: Instancia de DINOv2FeatureExtractor\n",
    "        k: N√∫mero de vecinos m√°s cercanos para scoring\n",
    "        coreset_ratio: Ratio de subsampling del memory bank (1.0 = sin subsampling)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        extractor: DINOv2FeatureExtractor, \n",
    "        k: int = 1,\n",
    "        coreset_ratio: float = 1.0\n",
    "    ):\n",
    "        self.extractor = extractor\n",
    "        self.k = k\n",
    "        self.coreset_ratio = coreset_ratio\n",
    "        self.memory_bank = None\n",
    "        \n",
    "    def build_memory_bank(self, good_images: List[Image.Image], verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Construye el banco de memoria con patches de im√°genes sin defectos.\n",
    "        \n",
    "        Args:\n",
    "            good_images: Lista de im√°genes PIL sin defectos (training set)\n",
    "            verbose: Si True, muestra progreso\n",
    "        \"\"\"\n",
    "        all_patches = []\n",
    "        \n",
    "        for i, img in enumerate(good_images):\n",
    "            patches = self.extractor.extract_patches(img)  # [N, D]\n",
    "            all_patches.append(patches)\n",
    "            \n",
    "            if verbose and (i + 1) % 10 == 0:\n",
    "                print(f\"Procesadas {i + 1}/{len(good_images)} im√°genes\")\n",
    "        \n",
    "        # Concatenar todos los patches\n",
    "        self.memory_bank = torch.cat(all_patches, dim=0)  # [total_patches, D]\n",
    "        \n",
    "        # Coreset subsampling (opcional, para reducir memoria)\n",
    "        if self.coreset_ratio < 1.0:\n",
    "            n_samples = int(len(self.memory_bank) * self.coreset_ratio)\n",
    "            indices = torch.randperm(len(self.memory_bank))[:n_samples]\n",
    "            self.memory_bank = self.memory_bank[indices]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Memory Bank construido: {self.memory_bank.shape[0]} patches, \"\n",
    "                  f\"dim={self.memory_bank.shape[1]}\")\n",
    "    \n",
    "    def compute_anomaly_map(\n",
    "        self, \n",
    "        test_image: Image.Image,\n",
    "        smooth_sigma: float = 0.8\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Calcula mapa de anomal√≠a comparando contra memory bank.\n",
    "        \n",
    "        Args:\n",
    "            test_image: Imagen a evaluar\n",
    "            smooth_sigma: Sigma para suavizado\n",
    "            \n",
    "        Returns:\n",
    "            anomaly_map: Mapa [H, W] sin suavizar\n",
    "            anomaly_map_smooth: Mapa [H, W] suavizado\n",
    "            image_score: Score de anomal√≠a a nivel de imagen\n",
    "        \"\"\"\n",
    "        if self.memory_bank is None:\n",
    "            raise RuntimeError(\"Primero ejecuta build_memory_bank()\")\n",
    "        \n",
    "        # Extraer patches de imagen test\n",
    "        test_patches = self.extractor.extract_patches(test_image)  # [N, D]\n",
    "        \n",
    "        # Calcular similitud con todo el memory bank\n",
    "        # sim[i, j] = similitud entre test_patch[i] y memory_patch[j]\n",
    "        sim_matrix = torch.mm(test_patches, self.memory_bank.t())  # [N, memory_size]\n",
    "        \n",
    "        # k-NN: obtener k vecinos m√°s similares\n",
    "        topk_sim, _ = sim_matrix.topk(self.k, dim=1)  # [N, k]\n",
    "        \n",
    "        # Anomal√≠a = 1 - similitud promedio de k vecinos\n",
    "        anomaly_scores = 1 - topk_sim.mean(dim=1)  # [N]\n",
    "        \n",
    "        # Reshape a grid 2D\n",
    "        h, w = self.extractor.get_grid_size(test_image)\n",
    "        anomaly_map = anomaly_scores.cpu().numpy().reshape(h, w)\n",
    "        \n",
    "        # Suavizado\n",
    "        anomaly_map_smooth = ndimage.gaussian_filter(anomaly_map, sigma=smooth_sigma)\n",
    "        \n",
    "        # Score a nivel de imagen (m√°ximo score de anomal√≠a)\n",
    "        image_score = anomaly_map_smooth.max()\n",
    "        \n",
    "        return anomaly_map, anomaly_map_smooth, image_score\n",
    "    \n",
    "    def predict_batch(\n",
    "        self,\n",
    "        test_images: List[Image.Image],\n",
    "        smooth_sigma: float = 0.8\n",
    "    ) -> Tuple[List[np.ndarray], List[float]]:\n",
    "        \"\"\"\n",
    "        Predice anomal√≠as para un batch de im√°genes.\n",
    "        \n",
    "        Returns:\n",
    "            anomaly_maps: Lista de mapas de anomal√≠a\n",
    "            image_scores: Lista de scores por imagen\n",
    "        \"\"\"\n",
    "        anomaly_maps = []\n",
    "        image_scores = []\n",
    "        \n",
    "        for img in test_images:\n",
    "            _, amap_smooth, score = self.compute_anomaly_map(img, smooth_sigma)\n",
    "            anomaly_maps.append(amap_smooth)\n",
    "            image_scores.append(score)\n",
    "        \n",
    "        return anomaly_maps, image_scores\n",
    "    \n",
    "    def visualize(\n",
    "        self,\n",
    "        test_image: Image.Image,\n",
    "        anomaly_map: np.ndarray,\n",
    "        image_score: float,\n",
    "        title: str = \"Memory Bank + k-NN - Detecci√≥n de Anomal√≠as\"\n",
    "    ):\n",
    "        \"\"\"Visualiza resultado de detecci√≥n.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        axes[0].imshow(test_image)\n",
    "        axes[0].set_title(\"Imagen Test\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(test_image)\n",
    "        im = axes[1].imshow(\n",
    "            anomaly_map, \n",
    "            cmap='jet', \n",
    "            alpha=0.5, \n",
    "            extent=(0, test_image.width, test_image.height, 0)\n",
    "        )\n",
    "        axes[1].set_title(f\"Mapa de Anomal√≠a (Score: {image_score:.4f})\")\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.suptitle(title, fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# UTILIDADES DE VISUALIZACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_layer_comparison(\n",
    "    extractor: DINOv2FeatureExtractor,\n",
    "    image: Image.Image,\n",
    "    layers_to_compare: List[int] = [0, 3, 6, 9, 12, -1]\n",
    "):\n",
    "    \"\"\"\n",
    "    Compara visualizaci√≥n PCA de diferentes capas del modelo.\n",
    "    \n",
    "    √ötil para elegir la capa √≥ptima para extracci√≥n de features.\n",
    "    \"\"\"\n",
    "    original_layer = extractor.layer_idx\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ax, layer_idx in zip(axes, layers_to_compare):\n",
    "        extractor.layer_idx = layer_idx\n",
    "        patches = extractor.extract_patches(image, normalize=False).cpu().numpy()\n",
    "        \n",
    "        # PCA a 3 componentes para RGB\n",
    "        pca = PCA(n_components=3)\n",
    "        pca_result = pca.fit_transform(patches)\n",
    "        \n",
    "        # Normalizar a [0, 1]\n",
    "        pca_min = pca_result.min(axis=0)\n",
    "        pca_max = pca_result.max(axis=0)\n",
    "        pca_norm = (pca_result - pca_min) / (pca_max - pca_min + 1e-8)\n",
    "        \n",
    "        h, w = extractor.get_grid_size(image)\n",
    "        pca_image = pca_norm.reshape(h, w, 3)\n",
    "        \n",
    "        layer_name = \"√öltima\" if layer_idx == -1 else str(layer_idx)\n",
    "        ax.imshow(pca_image)\n",
    "        ax.set_title(f\"Capa {layer_name}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    extractor.layer_idx = original_layer\n",
    "    plt.suptitle(\"Comparaci√≥n de Features por Capa (PCA‚ÜíRGB)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def upsample_anomaly_map(\n",
    "    anomaly_map: np.ndarray,\n",
    "    target_size: Tuple[int, int],\n",
    "    mode: str = 'bilinear'\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Escala el mapa de anomal√≠a al tama√±o de la imagen original.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_map: Mapa de anomal√≠a [H, W]\n",
    "        target_size: (height, width) objetivo\n",
    "        mode: 'bilinear' o 'nearest'\n",
    "    \"\"\"\n",
    "    amap_tensor = torch.from_numpy(anomaly_map).unsqueeze(0).unsqueeze(0).float()\n",
    "    \n",
    "    # align_corners solo para modos que lo soporten\n",
    "    if mode in ('nearest', 'area'):\n",
    "        upsampled = F.interpolate(amap_tensor, size=target_size, mode=mode)\n",
    "    else:\n",
    "        upsampled = F.interpolate(amap_tensor, size=target_size, mode=mode, align_corners=False)\n",
    "    \n",
    "    return upsampled.squeeze().numpy()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# M√âTRICAS DE EVALUACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "class AnomalyEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluador de m√©tricas para detecci√≥n de anomal√≠as.\n",
    "    \n",
    "    Calcula m√©tricas pixel-level y region-level comparando\n",
    "    mapas de anomal√≠a predichos contra ground truth masks.\n",
    "    \n",
    "    M√©tricas implementadas:\n",
    "    - Pixel-level: IoU, Dice, Precision, Recall, F1\n",
    "    - Region-level: PRO (Per-Region Overlap)\n",
    "    \n",
    "    Caracter√≠sticas mejoradas:\n",
    "    - auto_normalize: Normalizaci√≥n autom√°tica al rango [0, 1]\n",
    "    - Resize autom√°tico al tama√±o del ground truth\n",
    "    - Estad√≠sticas de diagn√≥stico en resultados\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold: float = 0.5, auto_normalize: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            threshold: Umbral para binarizar el mapa de anomal√≠a (0-1).\n",
    "                      Se aplica DESPU√âS de normalizar al rango [0, 1].\n",
    "            auto_normalize: Si True, normaliza autom√°ticamente el mapa\n",
    "                           al rango [0, 1] antes de aplicar el umbral.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.auto_normalize = auto_normalize\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_ground_truth(gt_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Carga una m√°scara ground truth como array binario.\n",
    "        \n",
    "        Args:\n",
    "            gt_path: Ruta a la imagen de ground truth\n",
    "            \n",
    "        Returns:\n",
    "            mask: Array binario [H, W] con valores 0 o 1\n",
    "        \"\"\"\n",
    "        gt_image = Image.open(gt_path).convert('L')\n",
    "        gt_array = np.array(gt_image)\n",
    "        # Binarizar (MVTec usa 255 para anomal√≠a, 0 para normal)\n",
    "        return (gt_array > 127).astype(np.float32)\n",
    "    \n",
    "    def binarize_anomaly_map(\n",
    "        self, \n",
    "        anomaly_map: np.ndarray, \n",
    "        threshold: float = None\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Binariza un mapa de anomal√≠a usando el umbral.\n",
    "        \n",
    "        Args:\n",
    "            anomaly_map: Mapa de anomal√≠a [H, W] con valores en [0, 1]\n",
    "            threshold: Umbral (usa self.threshold si es None)\n",
    "            \n",
    "        Returns:\n",
    "            binary_mask: M√°scara binaria [H, W]\n",
    "        \"\"\"\n",
    "        if threshold is None:\n",
    "            threshold = self.threshold\n",
    "        \n",
    "        # Normalizar a [0, 1] si es necesario\n",
    "        amap_min = anomaly_map.min()\n",
    "        amap_max = anomaly_map.max()\n",
    "        if amap_max > amap_min:\n",
    "            normalized = (anomaly_map - amap_min) / (amap_max - amap_min)\n",
    "        else:\n",
    "            normalized = np.zeros_like(anomaly_map)\n",
    "        \n",
    "        return (normalized >= threshold).astype(np.float32)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # PIXEL-LEVEL METRICS\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    def compute_pixel_metrics(\n",
    "        self, \n",
    "        pred_mask: np.ndarray, \n",
    "        gt_mask: np.ndarray\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Calcula m√©tricas a nivel de pixel.\n",
    "        \n",
    "        Args:\n",
    "            pred_mask: M√°scara predicha binaria [H, W]\n",
    "            gt_mask: Ground truth binario [H, W]\n",
    "            \n",
    "        Returns:\n",
    "            dict con: IoU, Dice, Precision, Recall, F1\n",
    "        \"\"\"\n",
    "        # Asegurar mismo tama√±o\n",
    "        if pred_mask.shape != gt_mask.shape:\n",
    "            pred_mask = upsample_anomaly_map(\n",
    "                pred_mask, \n",
    "                target_size=gt_mask.shape,\n",
    "                mode='nearest'\n",
    "            )\n",
    "        \n",
    "        pred = pred_mask.flatten().astype(bool)\n",
    "        gt = gt_mask.flatten().astype(bool)\n",
    "        \n",
    "        # Componentes de la matriz de confusi√≥n\n",
    "        tp = np.sum(pred & gt)        # True Positives\n",
    "        fp = np.sum(pred & ~gt)       # False Positives\n",
    "        fn = np.sum(~pred & gt)       # False Negatives\n",
    "        tn = np.sum(~pred & ~gt)      # True Negatives\n",
    "        \n",
    "        # M√©tricas\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        intersection = tp\n",
    "        union = tp + fp + fn\n",
    "        iou = intersection / union if union > 0 else 0.0\n",
    "        \n",
    "        dice = 2 * intersection / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'IoU': iou,\n",
    "            'Dice': dice,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "            'TP': int(tp),\n",
    "            'FP': int(fp),\n",
    "            'FN': int(fn),\n",
    "            'TN': int(tn)\n",
    "        }\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # REGION-LEVEL METRICS (PRO)\n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    def compute_pro_single(\n",
    "        self,\n",
    "        pred_mask: np.ndarray,\n",
    "        gt_mask: np.ndarray\n",
    "    ) -> Tuple[float, int, List[float]]:\n",
    "        \"\"\"\n",
    "        Calcula PRO para una sola imagen con un umbral fijo.\n",
    "        \n",
    "        F√≥rmula del paper:\n",
    "        PRO = (1/N) * Œ£_i Œ£_k (|P_i ‚à© C_{i,k}| / |C_{i,k}|)\n",
    "        \n",
    "        Donde:\n",
    "        - N = n√∫mero total de regiones conectadas en el ground truth\n",
    "        - C_{i,k} = p√≠xeles del componente k en imagen i\n",
    "        - P_i = p√≠xeles predichos como an√≥malos\n",
    "        \n",
    "        Args:\n",
    "            pred_mask: M√°scara binaria de predicci√≥n [H, W]\n",
    "            gt_mask: Ground truth binario [H, W]\n",
    "            \n",
    "        Returns:\n",
    "            pro_score: Score PRO para esta imagen (promedio sobre regiones)\n",
    "            num_regions: N√∫mero de regiones conectadas\n",
    "            region_overlaps: Lista de overlaps por regi√≥n\n",
    "        \"\"\"\n",
    "        from scipy import ndimage as ndi\n",
    "        \n",
    "        # Asegurar mismo tama√±o\n",
    "        if pred_mask.shape != gt_mask.shape:\n",
    "            pred_mask = upsample_anomaly_map(\n",
    "                pred_mask,\n",
    "                target_size=gt_mask.shape,\n",
    "                mode='nearest'\n",
    "            )\n",
    "        \n",
    "        # Encontrar regiones conectadas en ground truth\n",
    "        labeled_gt, num_regions = ndi.label(gt_mask > 0)\n",
    "        \n",
    "        if num_regions == 0:\n",
    "            return 1.0, 0, []\n",
    "        \n",
    "        # Calcular overlap para cada regi√≥n: |P ‚à© C_k| / |C_k|\n",
    "        region_overlaps = []\n",
    "        pred_binary = pred_mask > 0\n",
    "        \n",
    "        for region_id in range(1, num_regions + 1):\n",
    "            region_mask = (labeled_gt == region_id)\n",
    "            region_size = np.sum(region_mask)  # |C_k|\n",
    "            \n",
    "            if region_size > 0:\n",
    "                intersection = np.sum(pred_binary & region_mask)  # |P ‚à© C_k|\n",
    "                overlap = intersection / region_size\n",
    "                region_overlaps.append(overlap)\n",
    "        \n",
    "        # PRO para esta imagen = promedio sobre regiones\n",
    "        pro_score = np.mean(region_overlaps) if region_overlaps else 0.0\n",
    "        \n",
    "        return pro_score, num_regions, region_overlaps\n",
    "    \n",
    "    def compute_pro(\n",
    "        self, \n",
    "        anomaly_map: np.ndarray, \n",
    "        gt_mask: np.ndarray,\n",
    "        threshold: float = None\n",
    "    ) -> Tuple[float, int, List[float]]:\n",
    "        \"\"\"\n",
    "        Calcula PRO para un mapa de anomal√≠a usando un umbral.\n",
    "        \n",
    "        Args:\n",
    "            anomaly_map: Mapa de anomal√≠a [H, W] (valores continuos)\n",
    "            gt_mask: Ground truth binario [H, W]\n",
    "            threshold: Umbral para binarizar (usa self.threshold si None)\n",
    "            \n",
    "        Returns:\n",
    "            pro_score: Score PRO\n",
    "            num_regions: N√∫mero de regiones\n",
    "            region_overlaps: Overlaps por regi√≥n\n",
    "        \"\"\"\n",
    "        # Binarizar mapa de anomal√≠a\n",
    "        pred_mask = self.binarize_anomaly_map(anomaly_map, threshold)\n",
    "        return self.compute_pro_single(pred_mask, gt_mask)\n",
    "    \n",
    "    def compute_au_pro(\n",
    "        self, \n",
    "        anomaly_map: np.ndarray, \n",
    "        gt_mask: np.ndarray,\n",
    "        num_thresholds: int = 100,\n",
    "        fpr_limit: float = 0.3\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, float]:\n",
    "        \"\"\"\n",
    "        Calcula AU-PRO (Area Under PRO curve).\n",
    "        \n",
    "        Calcula la curva PRO vs FPR para m√∫ltiples umbrales y el √°rea\n",
    "        bajo la curva hasta un l√≠mite de FPR (t√≠picamente 0.3).\n",
    "        \n",
    "        Args:\n",
    "            anomaly_map: Mapa de anomal√≠a [H, W] (valores continuos)\n",
    "            gt_mask: Ground truth binario [H, W]\n",
    "            num_thresholds: N√∫mero de umbrales para la curva\n",
    "            fpr_limit: L√≠mite de FPR para integraci√≥n (default 0.3)\n",
    "            \n",
    "        Returns:\n",
    "            thresholds: Umbrales usados\n",
    "            fpr_values: FPR para cada umbral\n",
    "            pro_values: PRO para cada umbral\n",
    "            au_pro: √Årea bajo la curva PRO normalizada\n",
    "        \"\"\"\n",
    "        from scipy import ndimage as ndi\n",
    "        \n",
    "        # Asegurar mismo tama√±o\n",
    "        if anomaly_map.shape != gt_mask.shape:\n",
    "            anomaly_map = upsample_anomaly_map(\n",
    "                anomaly_map, \n",
    "                target_size=gt_mask.shape,\n",
    "                mode='bilinear'\n",
    "            )\n",
    "        \n",
    "        # Normalizar mapa a [0, 1]\n",
    "        amap_min = anomaly_map.min()\n",
    "        amap_max = anomaly_map.max()\n",
    "        if amap_max > amap_min:\n",
    "            anomaly_map_norm = (anomaly_map - amap_min) / (amap_max - amap_min)\n",
    "        else:\n",
    "            anomaly_map_norm = np.zeros_like(anomaly_map)\n",
    "        \n",
    "        # Encontrar regiones conectadas en ground truth\n",
    "        labeled_gt, num_regions = ndi.label(gt_mask > 0)\n",
    "        \n",
    "        if num_regions == 0:\n",
    "            return np.array([0.0]), np.array([0.0]), np.array([1.0]), 1.0\n",
    "        \n",
    "        # Calcular PRO y FPR para m√∫ltiples umbrales\n",
    "        thresholds = np.linspace(0, 1, num_thresholds)\n",
    "        fpr_values = []\n",
    "        pro_values = []\n",
    "        \n",
    "        total_normal_pixels = np.sum(gt_mask == 0)\n",
    "        \n",
    "        for thresh in thresholds:\n",
    "            pred_mask = (anomaly_map_norm >= thresh)\n",
    "            \n",
    "            # FPR: False Positive Rate en p√≠xeles normales\n",
    "            if total_normal_pixels > 0:\n",
    "                fp = np.sum(pred_mask & (gt_mask == 0))\n",
    "                fpr = fp / total_normal_pixels\n",
    "            else:\n",
    "                fpr = 0.0\n",
    "            \n",
    "            # PRO: (1/N) * Œ£_k (|P ‚à© C_k| / |C_k|)\n",
    "            region_overlaps = []\n",
    "            for region_id in range(1, num_regions + 1):\n",
    "                region_mask = (labeled_gt == region_id)\n",
    "                region_size = np.sum(region_mask)\n",
    "                \n",
    "                if region_size > 0:\n",
    "                    intersection = np.sum(pred_mask & region_mask)\n",
    "                    overlap = intersection / region_size\n",
    "                    region_overlaps.append(overlap)\n",
    "            \n",
    "            pro = np.mean(region_overlaps) if region_overlaps else 0.0\n",
    "            \n",
    "            fpr_values.append(fpr)\n",
    "            pro_values.append(pro)\n",
    "        \n",
    "        thresholds = np.array(thresholds)\n",
    "        fpr_values = np.array(fpr_values)\n",
    "        pro_values = np.array(pro_values)\n",
    "        \n",
    "        # Calcular AU-PRO (√°rea bajo curva hasta FPR limit)\n",
    "        valid_idx = fpr_values <= fpr_limit\n",
    "        \n",
    "        if np.sum(valid_idx) > 1:\n",
    "            # Ordenar por FPR e integrar\n",
    "            sorted_idx = np.argsort(fpr_values[valid_idx])\n",
    "            fpr_sorted = fpr_values[valid_idx][sorted_idx]\n",
    "            pro_sorted = pro_values[valid_idx][sorted_idx]\n",
    "            au_pro = np.trapz(pro_sorted, fpr_sorted) / fpr_limit\n",
    "        else:\n",
    "            au_pro = 0.0\n",
    "        \n",
    "        return thresholds, fpr_values, pro_values, au_pro\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        anomaly_map: np.ndarray,\n",
    "        gt_mask: np.ndarray,\n",
    "        threshold: float = None\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Eval√∫a todas las m√©tricas para un mapa de anomal√≠a.\n",
    "        \n",
    "        El proceso mejorado:\n",
    "        1. Guarda estad√≠sticas originales para diagn√≥stico\n",
    "        2. Resize autom√°tico al tama√±o del GT si difieren\n",
    "        3. Normaliza al rango [0, 1] (si auto_normalize=True)\n",
    "        4. Aplica umbral sobre valores normalizados\n",
    "        \n",
    "        Args:\n",
    "            anomaly_map: Mapa de anomal√≠a [H, W] (valores crudos del modelo)\n",
    "            gt_mask: Ground truth binario [H, W]\n",
    "            threshold: Umbral para binarizaci√≥n (0-1). Usa self.threshold si es None.\n",
    "            \n",
    "        Returns:\n",
    "            dict con m√©tricas + estad√≠sticas de diagn√≥stico:\n",
    "            - M√©tricas est√°ndar: IoU, Dice, Precision, Recall, F1, PRO, AU-PRO\n",
    "            - Estad√≠sticas: orig_min, orig_max, orig_mean, normalized\n",
    "        \"\"\"\n",
    "        use_threshold = threshold if threshold is not None else self.threshold\n",
    "        \n",
    "        # =====================================================================\n",
    "        # PASO 1: Guardar estad√≠sticas originales para diagn√≥stico\n",
    "        # =====================================================================\n",
    "        orig_min = float(anomaly_map.min())\n",
    "        orig_max = float(anomaly_map.max())\n",
    "        orig_mean = float(anomaly_map.mean())\n",
    "        orig_std = float(anomaly_map.std())\n",
    "        \n",
    "        # =====================================================================\n",
    "        # PASO 2: Resize autom√°tico al tama√±o del ground truth\n",
    "        # =====================================================================\n",
    "        if anomaly_map.shape != gt_mask.shape:\n",
    "            anomaly_map_resized = resize_anomaly_map(\n",
    "                anomaly_map,\n",
    "                target_size=gt_mask.shape,\n",
    "                interpolation='bilinear'\n",
    "            )\n",
    "        else:\n",
    "            anomaly_map_resized = anomaly_map.copy()\n",
    "        \n",
    "        # =====================================================================\n",
    "        # PASO 3: Normalizar al rango [0, 1] antes de aplicar umbral\n",
    "        # =====================================================================\n",
    "        if self.auto_normalize:\n",
    "            anomaly_map_normalized = normalize_anomaly_map(\n",
    "                anomaly_map_resized,\n",
    "                method='minmax'\n",
    "            )\n",
    "        else:\n",
    "            anomaly_map_normalized = anomaly_map_resized\n",
    "        \n",
    "        # =====================================================================\n",
    "        # PASO 4: Binarizar usando el umbral sobre valores normalizados [0, 1]\n",
    "        # =====================================================================\n",
    "        pred_mask = (anomaly_map_normalized >= use_threshold).astype(np.float32)\n",
    "        \n",
    "        # =====================================================================\n",
    "        # PASO 5: Calcular m√©tricas\n",
    "        # =====================================================================\n",
    "        # Pixel-level metrics\n",
    "        pixel_metrics = self.compute_pixel_metrics(pred_mask, gt_mask)\n",
    "        \n",
    "        # Region-level PRO (para el umbral seleccionado)\n",
    "        pro_score, num_regions, region_overlaps = self.compute_pro_single(pred_mask, gt_mask)\n",
    "        \n",
    "        # AU-PRO (√°rea bajo la curva PRO-FPR)\n",
    "        _, _, _, au_pro = self.compute_au_pro(anomaly_map_normalized, gt_mask)\n",
    "        \n",
    "        return {\n",
    "            **pixel_metrics,\n",
    "            'PRO': pro_score,\n",
    "            'AU-PRO': au_pro,\n",
    "            'Num_Regions': num_regions,\n",
    "            'Threshold': use_threshold,\n",
    "            # Estad√≠sticas de diagn√≥stico\n",
    "            'orig_min': orig_min,\n",
    "            'orig_max': orig_max,\n",
    "            'orig_mean': orig_mean,\n",
    "            'orig_std': orig_std,\n",
    "            'normalized': self.auto_normalize,\n",
    "            # Mapa normalizado para visualizaci√≥n\n",
    "            '_anomaly_map_normalized': anomaly_map_normalized,\n",
    "            '_pred_mask': pred_mask\n",
    "        }\n",
    "    \n",
    "    def visualize_comparison(\n",
    "        self,\n",
    "        test_image: Image.Image,\n",
    "        anomaly_map: np.ndarray,\n",
    "        gt_mask: np.ndarray,\n",
    "        metrics: dict,\n",
    "        title: str = \"Comparaci√≥n: Predicci√≥n vs Ground Truth\",\n",
    "        show_original_values: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Visualiza predicci√≥n vs ground truth con m√©tricas.\n",
    "        \n",
    "        Muestra 5 paneles:\n",
    "        1. Imagen original\n",
    "        2. Ground Truth\n",
    "        3. Mapa original (valores sin normalizar)\n",
    "        4. Mapa normalizado [0,1]\n",
    "        5. Predicci√≥n binarizada\n",
    "        \"\"\"\n",
    "        # Preparar datos\n",
    "        # Resize al tama√±o de la imagen para visualizaci√≥n\n",
    "        if anomaly_map.shape != gt_mask.shape:\n",
    "            amap_resized = resize_anomaly_map(anomaly_map, gt_mask.shape)\n",
    "        else:\n",
    "            amap_resized = anomaly_map.copy()\n",
    "        \n",
    "        # Guardar valores originales\n",
    "        amap_original = amap_resized.copy()\n",
    "        orig_min, orig_max = amap_original.min(), amap_original.max()\n",
    "        \n",
    "        # Normalizar\n",
    "        amap_normalized = normalize_anomaly_map(amap_resized, method='minmax')\n",
    "        \n",
    "        # Crear figura\n",
    "        n_cols = 5 if show_original_values else 4\n",
    "        fig, axes = plt.subplots(1, n_cols, figsize=(5 * n_cols, 5))\n",
    "        \n",
    "        ax_idx = 0\n",
    "        \n",
    "        # Panel 1: Imagen original\n",
    "        axes[ax_idx].imshow(test_image)\n",
    "        axes[ax_idx].set_title(\"Imagen Test\")\n",
    "        axes[ax_idx].axis('off')\n",
    "        ax_idx += 1\n",
    "        \n",
    "        # Panel 2: Ground Truth\n",
    "        axes[ax_idx].imshow(test_image)\n",
    "        axes[ax_idx].imshow(\n",
    "            resize_anomaly_map(gt_mask.astype(float), (test_image.height, test_image.width)),\n",
    "            cmap='Reds', alpha=0.5,\n",
    "            extent=(0, test_image.width, test_image.height, 0)\n",
    "        )\n",
    "        axes[ax_idx].set_title(f\"Ground Truth\\n({gt_mask.sum()} p√≠xeles)\")\n",
    "        axes[ax_idx].axis('off')\n",
    "        ax_idx += 1\n",
    "        \n",
    "        if show_original_values:\n",
    "            # Panel 3: Mapa original (sin normalizar)\n",
    "            axes[ax_idx].imshow(test_image)\n",
    "            im_orig = axes[ax_idx].imshow(\n",
    "                amap_original, \n",
    "                cmap='jet', \n",
    "                alpha=0.5,\n",
    "                extent=(0, test_image.width, test_image.height, 0)\n",
    "            )\n",
    "            axes[ax_idx].set_title(f\"Mapa Original\\n[{orig_min:.4f}, {orig_max:.4f}]\")\n",
    "            axes[ax_idx].axis('off')\n",
    "            plt.colorbar(im_orig, ax=axes[ax_idx], fraction=0.046, pad=0.04)\n",
    "            ax_idx += 1\n",
    "        \n",
    "        # Panel 4: Mapa normalizado\n",
    "        axes[ax_idx].imshow(test_image)\n",
    "        im_norm = axes[ax_idx].imshow(\n",
    "            amap_normalized, \n",
    "            cmap='jet', \n",
    "            alpha=0.5,\n",
    "            vmin=0, vmax=1,\n",
    "            extent=(0, test_image.width, test_image.height, 0)\n",
    "        )\n",
    "        axes[ax_idx].set_title(f\"Mapa Normalizado\\n[0.0, 1.0]\")\n",
    "        axes[ax_idx].axis('off')\n",
    "        plt.colorbar(im_norm, ax=axes[ax_idx], fraction=0.046, pad=0.04)\n",
    "        ax_idx += 1\n",
    "        \n",
    "        # Panel 5: Predicci√≥n binarizada\n",
    "        pred_binary = amap_normalized >= self.threshold\n",
    "        axes[ax_idx].imshow(test_image)\n",
    "        axes[ax_idx].imshow(\n",
    "            pred_binary, \n",
    "            cmap='Blues', \n",
    "            alpha=0.5,\n",
    "            extent=(0, test_image.width, test_image.height, 0)\n",
    "        )\n",
    "        n_pred = pred_binary.sum()\n",
    "        axes[ax_idx].set_title(f\"Predicci√≥n Binaria\\n(œÑ={self.threshold}, {n_pred} p√≠xeles)\")\n",
    "        axes[ax_idx].axis('off')\n",
    "        \n",
    "        # M√©tricas como texto\n",
    "        metrics_text = (\n",
    "            f\"IoU: {metrics['IoU']:.3f} | \"\n",
    "            f\"Dice: {metrics['Dice']:.3f} | \"\n",
    "            f\"F1: {metrics['F1']:.3f} | \"\n",
    "            f\"Precision: {metrics['Precision']:.3f} | \"\n",
    "            f\"Recall: {metrics['Recall']:.3f} | \"\n",
    "            f\"AU-PRO: {metrics['AU-PRO']:.3f}\"\n",
    "        )\n",
    "        \n",
    "        plt.figtext(0.5, 0.02, metrics_text, ha='center', fontsize=10,\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.suptitle(title, fontsize=14)\n",
    "        plt.tight_layout(rect=[0, 0.06, 1, 0.96])\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "def load_test_with_ground_truth(\n",
    "    test_folder: str,\n",
    "    gt_folder: str,\n",
    "    n_images: int = None\n",
    ") -> List[Tuple[Image.Image, np.ndarray, str]]:\n",
    "    \"\"\"\n",
    "    Carga im√°genes de test junto con sus ground truth masks.\n",
    "    \n",
    "    Args:\n",
    "        test_folder: Carpeta con im√°genes de test (ej: .../test/broken_large)\n",
    "        gt_folder: Carpeta con ground truth (ej: .../ground_truth/broken_large)\n",
    "        n_images: N√∫mero de im√°genes a cargar (None = todas)\n",
    "        \n",
    "    Returns:\n",
    "        Lista de tuplas (test_image, gt_mask, filename)\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    extensions = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "    \n",
    "    test_files = sorted([\n",
    "        f for f in os.listdir(test_folder)\n",
    "        if f.lower().endswith(extensions)\n",
    "    ])\n",
    "    \n",
    "    if n_images is not None:\n",
    "        test_files = test_files[:n_images]\n",
    "    \n",
    "    results = []\n",
    "    for filename in test_files:\n",
    "        # Cargar imagen test\n",
    "        test_path = os.path.join(test_folder, filename)\n",
    "        test_img = Image.open(test_path).convert(\"RGB\")\n",
    "        \n",
    "        # Cargar ground truth (mismo nombre, extensi√≥n _mask.png en MVTec)\n",
    "        gt_filename = filename.replace('.png', '_mask.png')\n",
    "        gt_path = os.path.join(gt_folder, gt_filename)\n",
    "        \n",
    "        if os.path.exists(gt_path):\n",
    "            gt_mask = AnomalyEvaluator.load_ground_truth(gt_path)\n",
    "        else:\n",
    "            # Intentar con el mismo nombre\n",
    "            gt_path = os.path.join(gt_folder, filename)\n",
    "            if os.path.exists(gt_path):\n",
    "                gt_mask = AnomalyEvaluator.load_ground_truth(gt_path)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Ground truth no encontrado para {filename}\")\n",
    "                gt_mask = None\n",
    "        \n",
    "        if gt_mask is not None:\n",
    "            results.append((test_img, gt_mask, filename))\n",
    "    \n",
    "    print(f\"Cargados {len(results)} pares (test, ground_truth) de {test_folder}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EJEMPLO DE USO\n",
    "# =============================================================================\n",
    "\n",
    "def load_images_from_folder(\n",
    "    folder_path: str, \n",
    "    n_images: int = None, \n",
    "    extensions: tuple = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    ") -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Carga N im√°genes de una carpeta.\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Ruta a la carpeta con im√°genes\n",
    "        n_images: N√∫mero de im√°genes a cargar (None = todas)\n",
    "        extensions: Extensiones de archivo v√°lidas\n",
    "        \n",
    "    Returns:\n",
    "        Lista de im√°genes PIL\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Obtener lista de archivos de imagen\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(folder_path) \n",
    "        if f.lower().endswith(extensions)\n",
    "    ])\n",
    "    \n",
    "    # Limitar a N im√°genes si se especifica\n",
    "    if n_images is not None:\n",
    "        image_files = image_files[:n_images]\n",
    "    \n",
    "    # Cargar im√°genes\n",
    "    images = []\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        images.append(img)\n",
    "    \n",
    "    print(f\"Cargadas {len(images)} im√°genes de {folder_path}\")\n",
    "    return images\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUADOR COMPLETO MVTEC AD\n",
    "# =============================================================================\n",
    "\n",
    "class MVTecDatasetEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluador completo del dataset MVTec AD.\n",
    "    \n",
    "    Itera sobre todas las categor√≠as y tipos de anomal√≠a,\n",
    "    calcula m√©tricas globales, por clase y por anomal√≠a.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Ruta base al dataset MVTec AD (contiene las 15 carpetas de categor√≠as)\n",
    "        model_path: Ruta al modelo DINOv2\n",
    "        layer_idx: √çndice de la capa a usar (-1 = √∫ltima)\n",
    "        n_good_images: N√∫mero de im√°genes \"good\" para memory bank (None = todas)\n",
    "        k: N√∫mero de vecinos para k-NN\n",
    "        coreset_ratio: Ratio de subsampling del memory bank\n",
    "        threshold: Umbral para binarizaci√≥n\n",
    "        auto_normalize: Si True, normaliza mapas de anomal√≠a autom√°ticamente\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista de las 15 categor√≠as de MVTec AD\n",
    "    CATEGORIES = [\n",
    "        'bottle', 'cable', 'capsule', 'carpet', 'grid',\n",
    "        'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n",
    "        'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n",
    "    ]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        model_path: str,\n",
    "        layer_idx: int = -1,\n",
    "        n_good_images: int = None,\n",
    "        k: int = 1,\n",
    "        coreset_ratio: float = 1.0,\n",
    "        threshold: float = 0.5,\n",
    "        auto_normalize: bool = True,\n",
    "        device: str = None\n",
    "    ):\n",
    "        import os\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.model_path = model_path\n",
    "        self.layer_idx = layer_idx\n",
    "        self.n_good_images = n_good_images\n",
    "        self.k = k\n",
    "        self.coreset_ratio = coreset_ratio\n",
    "        self.threshold = threshold\n",
    "        self.auto_normalize = auto_normalize\n",
    "        self.device = device\n",
    "        \n",
    "        # Crear extractor de features\n",
    "        self.extractor = DINOv2FeatureExtractor(\n",
    "            model_path=model_path,\n",
    "            layer_idx=layer_idx,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Evaluador de m√©tricas\n",
    "        self.evaluator = AnomalyEvaluator(\n",
    "            threshold=threshold,\n",
    "            auto_normalize=auto_normalize\n",
    "        )\n",
    "        \n",
    "        # Descubrir categor√≠as disponibles\n",
    "        self.available_categories = self._discover_categories()\n",
    "        print(f\"üîç Encontradas {len(self.available_categories)} categor√≠as en {dataset_path}\")\n",
    "    \n",
    "    def _discover_categories(self) -> List[str]:\n",
    "        \"\"\"Descubre las categor√≠as disponibles en el dataset.\"\"\"\n",
    "        import os\n",
    "        categories = []\n",
    "        for cat in self.CATEGORIES:\n",
    "            cat_path = os.path.join(self.dataset_path, cat)\n",
    "            if os.path.isdir(cat_path):\n",
    "                categories.append(cat)\n",
    "        return categories\n",
    "    \n",
    "    def _get_anomaly_types(self, category: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Obtiene los tipos de anomal√≠a para una categor√≠a (excluyendo 'good').\n",
    "        Solo incluye tipos que tienen ground truth disponible.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        test_path = os.path.join(self.dataset_path, category, 'test')\n",
    "        gt_path = os.path.join(self.dataset_path, category, 'ground_truth')\n",
    "        \n",
    "        anomaly_types = []\n",
    "        if os.path.isdir(test_path):\n",
    "            for folder in sorted(os.listdir(test_path)):\n",
    "                folder_path = os.path.join(test_path, folder)\n",
    "                gt_folder_path = os.path.join(gt_path, folder)\n",
    "                # Solo incluir si no es 'good' y tiene ground truth\n",
    "                if os.path.isdir(folder_path) and folder != 'good':\n",
    "                    if os.path.isdir(gt_folder_path):\n",
    "                        anomaly_types.append(folder)\n",
    "        return anomaly_types\n",
    "    \n",
    "    def _load_good_images(self, category: str) -> List[Image.Image]:\n",
    "        \"\"\"Carga im√°genes 'good' del training set para una categor√≠a.\"\"\"\n",
    "        import os\n",
    "        good_path = os.path.join(self.dataset_path, category, 'train', 'good')\n",
    "        return load_images_from_folder(good_path, n_images=self.n_good_images)\n",
    "    \n",
    "    def _build_memory_bank(self, category: str, verbose: bool = True) -> MemoryBankDetector:\n",
    "        \"\"\"Construye el memory bank para una categor√≠a.\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\nüì¶ Construyendo Memory Bank para '{category}'...\")\n",
    "        \n",
    "        good_images = self._load_good_images(category)\n",
    "        \n",
    "        detector = MemoryBankDetector(\n",
    "            extractor=self.extractor,\n",
    "            k=self.k,\n",
    "            coreset_ratio=self.coreset_ratio\n",
    "        )\n",
    "        detector.build_memory_bank(good_images, verbose=verbose)\n",
    "        \n",
    "        return detector\n",
    "    \n",
    "    def evaluate_category(\n",
    "        self,\n",
    "        category: str,\n",
    "        detector: MemoryBankDetector = None,\n",
    "        verbose: bool = True\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Eval√∫a todas las anomal√≠as de una categor√≠a.\n",
    "        \n",
    "        Args:\n",
    "            category: Nombre de la categor√≠a\n",
    "            detector: Memory bank detector (si None, se construye uno nuevo)\n",
    "            verbose: Si True, muestra progreso\n",
    "            \n",
    "        Returns:\n",
    "            dict con m√©tricas por anomal√≠a y resumen de la categor√≠a\n",
    "        \"\"\"\n",
    "        import os\n",
    "        \n",
    "        if detector is None:\n",
    "            detector = self._build_memory_bank(category, verbose)\n",
    "        \n",
    "        anomaly_types = self._get_anomaly_types(category)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nüîç Evaluando {len(anomaly_types)} tipos de anomal√≠a en '{category}'\")\n",
    "        \n",
    "        category_results = {\n",
    "            'category': category,\n",
    "            'anomaly_results': {},\n",
    "            'all_metrics': [],\n",
    "            'summary': {}\n",
    "        }\n",
    "        \n",
    "        for anomaly_type in anomaly_types:\n",
    "            test_folder = os.path.join(self.dataset_path, category, 'test', anomaly_type)\n",
    "            gt_folder = os.path.join(self.dataset_path, category, 'ground_truth', anomaly_type)\n",
    "            \n",
    "            if not os.path.isdir(gt_folder):\n",
    "                if verbose:\n",
    "                    print(f\"  ‚ö†Ô∏è Sin ground truth para {anomaly_type}, saltando...\")\n",
    "                continue\n",
    "            \n",
    "            # Cargar pares test/ground_truth\n",
    "            test_data = load_test_with_ground_truth(\n",
    "                test_folder=test_folder,\n",
    "                gt_folder=gt_folder,\n",
    "                n_images=None  # Todas las im√°genes\n",
    "            )\n",
    "            \n",
    "            if len(test_data) == 0:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚ö†Ô∏è No hay datos para {anomaly_type}\")\n",
    "                continue\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n  üìç Tipo: {anomaly_type} ({len(test_data)} im√°genes)\")\n",
    "            \n",
    "            anomaly_metrics = []\n",
    "            \n",
    "            for test_img, gt_mask, filename in test_data:\n",
    "                # Calcular mapa de anomal√≠a\n",
    "                amap, amap_smooth, score = detector.compute_anomaly_map(test_img)\n",
    "                \n",
    "                # Evaluar m√©tricas\n",
    "                metrics = self.evaluator.evaluate(amap_smooth, gt_mask)\n",
    "                metrics['filename'] = filename\n",
    "                metrics['category'] = category\n",
    "                metrics['anomaly_type'] = anomaly_type\n",
    "                metrics['image_score'] = score\n",
    "                \n",
    "                anomaly_metrics.append(metrics)\n",
    "            \n",
    "            # Calcular promedios para este tipo de anomal√≠a\n",
    "            anomaly_summary = self._compute_summary(anomaly_metrics)\n",
    "            anomaly_summary['n_images'] = len(anomaly_metrics)\n",
    "            \n",
    "            category_results['anomaly_results'][anomaly_type] = {\n",
    "                'metrics': anomaly_metrics,\n",
    "                'summary': anomaly_summary\n",
    "            }\n",
    "            category_results['all_metrics'].extend(anomaly_metrics)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"     IoU: {anomaly_summary['IoU']:.4f} | \"\n",
    "                      f\"Dice: {anomaly_summary['Dice']:.4f} | \"\n",
    "                      f\"F1: {anomaly_summary['F1']:.4f} | \"\n",
    "                      f\"AU-PRO: {anomaly_summary['AU-PRO']:.4f}\")\n",
    "        \n",
    "        # Resumen de la categor√≠a completa\n",
    "        if category_results['all_metrics']:\n",
    "            category_results['summary'] = self._compute_summary(category_results['all_metrics'])\n",
    "            category_results['summary']['n_images'] = len(category_results['all_metrics'])\n",
    "            category_results['summary']['n_anomaly_types'] = len(anomaly_types)\n",
    "        \n",
    "        return category_results\n",
    "    \n",
    "    def _compute_summary(self, metrics_list: List[dict]) -> dict:\n",
    "        \"\"\"Calcula m√©tricas promedio de una lista de m√©tricas.\"\"\"\n",
    "        if not metrics_list:\n",
    "            return {}\n",
    "        \n",
    "        summary = {}\n",
    "        metric_keys = ['IoU', 'Dice', 'Precision', 'Recall', 'F1', 'PRO', 'AU-PRO']\n",
    "        \n",
    "        for key in metric_keys:\n",
    "            values = [m[key] for m in metrics_list if key in m]\n",
    "            if values:\n",
    "                summary[key] = np.mean(values)\n",
    "                summary[f'{key}_std'] = np.std(values)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def evaluate_all(\n",
    "        self,\n",
    "        categories: List[str] = None,\n",
    "        verbose: bool = True,\n",
    "        save_results: bool = True,\n",
    "        output_path: str = None\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Eval√∫a todas las categor√≠as (o las especificadas).\n",
    "        \n",
    "        Args:\n",
    "            categories: Lista de categor√≠as a evaluar (None = todas)\n",
    "            verbose: Si True, muestra progreso detallado\n",
    "            save_results: Si True, guarda resultados en JSON\n",
    "            output_path: Ruta para guardar resultados (si save_results=True)\n",
    "            \n",
    "        Returns:\n",
    "            dict con resultados completos: por categor√≠a, por anomal√≠a y globales\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import json\n",
    "        from datetime import datetime\n",
    "        \n",
    "        if categories is None:\n",
    "            categories = self.available_categories\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üöÄ EVALUACI√ìN COMPLETA DEL DATASET MVTEC AD\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"   Modelo: {self.model_path}\")\n",
    "        print(f\"   Capa: {self.layer_idx}\")\n",
    "        print(f\"   k-NN: k={self.k}\")\n",
    "        print(f\"   Umbral: {self.threshold}\")\n",
    "        print(f\"   Categor√≠as: {len(categories)}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        all_results = {\n",
    "            'config': {\n",
    "                'model_path': self.model_path,\n",
    "                'layer_idx': self.layer_idx,\n",
    "                'k': self.k,\n",
    "                'coreset_ratio': self.coreset_ratio,\n",
    "                'threshold': self.threshold,\n",
    "                'auto_normalize': self.auto_normalize,\n",
    "                'n_good_images': self.n_good_images,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            },\n",
    "            'category_results': {},\n",
    "            'global_metrics': [],\n",
    "            'summary_by_category': {},\n",
    "            'summary_by_anomaly_type': {},\n",
    "            'global_summary': {}\n",
    "        }\n",
    "        \n",
    "        for i, category in enumerate(categories, 1):\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"üìÇ [{i}/{len(categories)}] Categor√≠a: {category.upper()}\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            try:\n",
    "                cat_results = self.evaluate_category(category, verbose=verbose)\n",
    "                all_results['category_results'][category] = cat_results\n",
    "                all_results['global_metrics'].extend(cat_results['all_metrics'])\n",
    "                all_results['summary_by_category'][category] = cat_results['summary']\n",
    "                \n",
    "                # Agregar m√©tricas por tipo de anomal√≠a al resumen global\n",
    "                for anomaly_type, anom_data in cat_results['anomaly_results'].items():\n",
    "                    key = f\"{category}/{anomaly_type}\"\n",
    "                    all_results['summary_by_anomaly_type'][key] = anom_data['summary']\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error procesando {category}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Calcular m√©tricas globales\n",
    "        if all_results['global_metrics']:\n",
    "            all_results['global_summary'] = self._compute_summary(all_results['global_metrics'])\n",
    "            all_results['global_summary']['n_total_images'] = len(all_results['global_metrics'])\n",
    "            all_results['global_summary']['n_categories'] = len(categories)\n",
    "        \n",
    "        # Imprimir resumen final\n",
    "        self._print_final_summary(all_results)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        if save_results:\n",
    "            if output_path is None:\n",
    "                output_path = os.path.join(\n",
    "                    self.dataset_path, '..', \n",
    "                    f'evaluation_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "                )\n",
    "            self._save_results(all_results, output_path)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def _print_final_summary(self, results: dict):\n",
    "        \"\"\"Imprime el resumen final de la evaluaci√≥n.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä RESUMEN FINAL DE EVALUACI√ìN\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Resumen por categor√≠a\n",
    "        print(\"\\nüè∑Ô∏è  M√âTRICAS POR CATEGOR√çA:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Categor√≠a':<15} {'IoU':<10} {'Dice':<10} {'F1':<10} {'Precision':<10} {'Recall':<10} {'AU-PRO':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for category, summary in results['summary_by_category'].items():\n",
    "            if summary:\n",
    "                print(f\"{category:<15} \"\n",
    "                      f\"{summary.get('IoU', 0):<10.4f} \"\n",
    "                      f\"{summary.get('Dice', 0):<10.4f} \"\n",
    "                      f\"{summary.get('F1', 0):<10.4f} \"\n",
    "                      f\"{summary.get('Precision', 0):<10.4f} \"\n",
    "                      f\"{summary.get('Recall', 0):<10.4f} \"\n",
    "                      f\"{summary.get('AU-PRO', 0):<10.4f}\")\n",
    "        \n",
    "        # Resumen global\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üåç M√âTRICAS GLOBALES:\")\n",
    "        print(\"=\" * 80)\n",
    "        gs = results['global_summary']\n",
    "        if gs:\n",
    "            print(f\"   Total im√°genes evaluadas: {gs.get('n_total_images', 0)}\")\n",
    "            print(f\"   Total categor√≠as: {gs.get('n_categories', 0)}\")\n",
    "            print()\n",
    "            print(f\"   üìà M√©tricas Pixel-Level:\")\n",
    "            print(f\"      IoU:       {gs.get('IoU', 0):.4f} (¬± {gs.get('IoU_std', 0):.4f})\")\n",
    "            print(f\"      Dice:      {gs.get('Dice', 0):.4f} (¬± {gs.get('Dice_std', 0):.4f})\")\n",
    "            print(f\"      Precision: {gs.get('Precision', 0):.4f} (¬± {gs.get('Precision_std', 0):.4f})\")\n",
    "            print(f\"      Recall:    {gs.get('Recall', 0):.4f} (¬± {gs.get('Recall_std', 0):.4f})\")\n",
    "            print(f\"      F1:        {gs.get('F1', 0):.4f} (¬± {gs.get('F1_std', 0):.4f})\")\n",
    "            print()\n",
    "            print(f\"   üìà M√©tricas Region-Level:\")\n",
    "            print(f\"      PRO:       {gs.get('PRO', 0):.4f} (¬± {gs.get('PRO_std', 0):.4f})\")\n",
    "            print(f\"      AU-PRO:    {gs.get('AU-PRO', 0):.4f} (¬± {gs.get('AU-PRO_std', 0):.4f})\")\n",
    "    \n",
    "    def _save_results(self, results: dict, output_path: str):\n",
    "        \"\"\"Guarda los resultados en formato JSON.\"\"\"\n",
    "        import json\n",
    "        import os\n",
    "        \n",
    "        # Eliminar datos internos que no son serializables\n",
    "        results_clean = self._clean_results_for_json(results)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results_clean, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nüíæ Resultados guardados en: {output_path}\")\n",
    "    \n",
    "    def _clean_results_for_json(self, results: dict) -> dict:\n",
    "        \"\"\"Limpia los resultados para serializaci√≥n JSON.\"\"\"\n",
    "        import copy\n",
    "        \n",
    "        def clean_value(v):\n",
    "            if isinstance(v, (np.floating, np.integer)):\n",
    "                return float(v)\n",
    "            elif isinstance(v, np.ndarray):\n",
    "                return v.tolist()\n",
    "            elif isinstance(v, dict):\n",
    "                return {k: clean_value(val) for k, val in v.items() \n",
    "                       if not k.startswith('_')}\n",
    "            elif isinstance(v, list):\n",
    "                return [clean_value(item) for item in v]\n",
    "            else:\n",
    "                return v\n",
    "        \n",
    "        return clean_value(results)\n",
    "    \n",
    "    def generate_report(\n",
    "        self,\n",
    "        results: dict,\n",
    "        output_path: str = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Genera un reporte detallado en formato Markdown.\n",
    "        \n",
    "        Args:\n",
    "            results: Resultados de evaluate_all()\n",
    "            output_path: Ruta para guardar el reporte (opcional)\n",
    "            \n",
    "        Returns:\n",
    "            Contenido del reporte en Markdown\n",
    "        \"\"\"\n",
    "        from datetime import datetime\n",
    "        import os\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"# üìä Reporte de Evaluaci√≥n MVTec AD\")\n",
    "        report.append(f\"\\n**Fecha:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        # Configuraci√≥n\n",
    "        config = results.get('config', {})\n",
    "        report.append(\"## ‚öôÔ∏è Configuraci√≥n\\n\")\n",
    "        report.append(f\"- **Modelo:** `{config.get('model_path', 'N/A')}`\")\n",
    "        report.append(f\"- **Capa DINOv2:** {config.get('layer_idx', 'N/A')}\")\n",
    "        report.append(f\"- **k-NN (k):** {config.get('k', 'N/A')}\")\n",
    "        report.append(f\"- **Umbral:** {config.get('threshold', 'N/A')}\")\n",
    "        report.append(f\"- **Im√°genes 'good' para Memory Bank:** {config.get('n_good_images', 'Todas')}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Resumen global\n",
    "        gs = results.get('global_summary', {})\n",
    "        report.append(\"## üåç M√©tricas Globales\\n\")\n",
    "        report.append(f\"- **Total im√°genes evaluadas:** {gs.get('n_total_images', 0)}\")\n",
    "        report.append(f\"- **Total categor√≠as:** {gs.get('n_categories', 0)}\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"| M√©trica | Valor | Desv. Est. |\")\n",
    "        report.append(\"|---------|-------|------------|\")\n",
    "        for metric in ['IoU', 'Dice', 'Precision', 'Recall', 'F1', 'PRO', 'AU-PRO']:\n",
    "            val = gs.get(metric, 0)\n",
    "            std = gs.get(f'{metric}_std', 0)\n",
    "            report.append(f\"| {metric} | {val:.4f} | ¬± {std:.4f} |\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Tabla por categor√≠a\n",
    "        report.append(\"## üè∑Ô∏è M√©tricas por Categor√≠a\\n\")\n",
    "        report.append(\"| Categor√≠a | IoU | Dice | F1 | Precision | Recall | AU-PRO |\")\n",
    "        report.append(\"|-----------|-----|------|----|-----------|----- --|--------|\")\n",
    "        \n",
    "        for category, summary in results.get('summary_by_category', {}).items():\n",
    "            if summary:\n",
    "                report.append(\n",
    "                    f\"| {category} | \"\n",
    "                    f\"{summary.get('IoU', 0):.4f} | \"\n",
    "                    f\"{summary.get('Dice', 0):.4f} | \"\n",
    "                    f\"{summary.get('F1', 0):.4f} | \"\n",
    "                    f\"{summary.get('Precision', 0):.4f} | \"\n",
    "                    f\"{summary.get('Recall', 0):.4f} | \"\n",
    "                    f\"{summary.get('AU-PRO', 0):.4f} |\"\n",
    "                )\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Detalle por tipo de anomal√≠a\n",
    "        report.append(\"## üî¨ Detalle por Tipo de Anomal√≠a\\n\")\n",
    "        \n",
    "        for category, cat_data in results.get('category_results', {}).items():\n",
    "            report.append(f\"### {category.upper()}\\n\")\n",
    "            report.append(\"| Tipo de Anomal√≠a | Im√°genes | IoU | Dice | F1 | AU-PRO |\")\n",
    "            report.append(\"|------------------|----------|-----|------|----|----- --|\")\n",
    "            \n",
    "            for anomaly_type, anom_data in cat_data.get('anomaly_results', {}).items():\n",
    "                summary = anom_data.get('summary', {})\n",
    "                report.append(\n",
    "                    f\"| {anomaly_type} | \"\n",
    "                    f\"{summary.get('n_images', 0)} | \"\n",
    "                    f\"{summary.get('IoU', 0):.4f} | \"\n",
    "                    f\"{summary.get('Dice', 0):.4f} | \"\n",
    "                    f\"{summary.get('F1', 0):.4f} | \"\n",
    "                    f\"{summary.get('AU-PRO', 0):.4f} |\"\n",
    "                )\n",
    "            report.append(\"\")\n",
    "        \n",
    "        report_content = \"\\n\".join(report)\n",
    "        \n",
    "        # Guardar si se especifica ruta\n",
    "        if output_path:\n",
    "            os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_content)\n",
    "            print(f\"\\nüìù Reporte guardado en: {output_path}\")\n",
    "        \n",
    "        return report_content\n",
    "\n",
    "\n",
    "class MVTecDatasetEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluador completo del dataset MVTec AD.\n",
    "    \n",
    "    Itera sobre todas las categor√≠as y tipos de anomal√≠a,\n",
    "    calcula m√©tricas globales, por clase y por anomal√≠a.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Ruta base al dataset MVTec AD (contiene las 15 carpetas de categor√≠as)\n",
    "        model_path: Ruta al modelo DINOv2\n",
    "        layer_idx: √çndice de la capa a usar (-1 = √∫ltima)\n",
    "        n_good_images: N√∫mero de im√°genes \"good\" para memory bank (None = todas)\n",
    "        k: N√∫mero de vecinos para k-NN\n",
    "        coreset_ratio: Ratio de subsampling del memory bank\n",
    "        threshold: Umbral para binarizaci√≥n\n",
    "        auto_normalize: Si True, normaliza mapas de anomal√≠a autom√°ticamente\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lista de las 15 categor√≠as de MVTec AD\n",
    "    CATEGORIES = [\n",
    "        'bottle', 'cable', 'capsule', 'carpet', 'grid',\n",
    "        'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n",
    "        'tile', 'toothbrush', 'transistor', 'wood', 'zipper'\n",
    "    ]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path: str,\n",
    "        model_path: str,\n",
    "        layer_idx: int = -1,\n",
    "        n_good_images: int = None,\n",
    "        k: int = 1,\n",
    "        coreset_ratio: float = 1.0,\n",
    "        threshold: float = 0.5,\n",
    "        auto_normalize: bool = True,\n",
    "        device: str = None\n",
    "    ):\n",
    "        import os\n",
    "        \n",
    "        self.dataset_path = dataset_path\n",
    "        self.model_path = model_path\n",
    "        self.layer_idx = layer_idx\n",
    "        self.n_good_images = n_good_images\n",
    "        self.k = k\n",
    "        self.coreset_ratio = coreset_ratio\n",
    "        self.threshold = threshold\n",
    "        self.auto_normalize = auto_normalize\n",
    "        self.device = device\n",
    "        \n",
    "        # Crear extractor de features\n",
    "        self.extractor = DINOv2FeatureExtractor(\n",
    "            model_path=model_path,\n",
    "            layer_idx=layer_idx,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Evaluador de m√©tricas\n",
    "        self.evaluator = AnomalyEvaluator(\n",
    "            threshold=threshold,\n",
    "            auto_normalize=auto_normalize\n",
    "        )\n",
    "        \n",
    "        # Descubrir categor√≠as disponibles\n",
    "        self.available_categories = self._discover_categories()\n",
    "        print(f\"üîç Encontradas {len(self.available_categories)} categor√≠as en {dataset_path}\")\n",
    "    \n",
    "    def _discover_categories(self) -> List[str]:\n",
    "        \"\"\"Descubre las categor√≠as disponibles en el dataset.\"\"\"\n",
    "        import os\n",
    "        categories = []\n",
    "        for cat in self.CATEGORIES:\n",
    "            cat_path = os.path.join(self.dataset_path, cat)\n",
    "            if os.path.isdir(cat_path):\n",
    "                categories.append(cat)\n",
    "        return categories\n",
    "    \n",
    "    def _get_anomaly_types(self, category: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Obtiene los tipos de anomal√≠a para una categor√≠a (excluyendo 'good').\n",
    "        Solo incluye tipos que tienen ground truth disponible.\n",
    "        \"\"\"\n",
    "        import os\n",
    "        test_path = os.path.join(self.dataset_path, category, 'test')\n",
    "        gt_path = os.path.join(self.dataset_path, category, 'ground_truth')\n",
    "        \n",
    "        anomaly_types = []\n",
    "        if os.path.isdir(test_path):\n",
    "            for folder in sorted(os.listdir(test_path)):\n",
    "                folder_path = os.path.join(test_path, folder)\n",
    "                gt_folder_path = os.path.join(gt_path, folder)\n",
    "                # Solo incluir si no es 'good' y tiene ground truth\n",
    "                if os.path.isdir(folder_path) and folder != 'good':\n",
    "                    if os.path.isdir(gt_folder_path):\n",
    "                        anomaly_types.append(folder)\n",
    "        return anomaly_types\n",
    "    \n",
    "    def _load_good_images(self, category: str) -> List[Image.Image]:\n",
    "        \"\"\"Carga im√°genes 'good' del training set para una categor√≠a.\"\"\"\n",
    "        import os\n",
    "        good_path = os.path.join(self.dataset_path, category, 'train', 'good')\n",
    "        return load_images_from_folder(good_path, n_images=self.n_good_images)\n",
    "    \n",
    "    def _build_memory_bank(self, category: str, verbose: bool = True) -> MemoryBankDetector:\n",
    "        \"\"\"Construye el memory bank para una categor√≠a.\"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\nüì¶ Construyendo Memory Bank para '{category}'...\")\n",
    "        \n",
    "        good_images = self._load_good_images(category)\n",
    "        \n",
    "        detector = MemoryBankDetector(\n",
    "            extractor=self.extractor,\n",
    "            k=self.k,\n",
    "            coreset_ratio=self.coreset_ratio\n",
    "        )\n",
    "        detector.build_memory_bank(good_images, verbose=verbose)\n",
    "        \n",
    "        return detector\n",
    "    \n",
    "    def evaluate_category(\n",
    "        self,\n",
    "        category: str,\n",
    "        detector: MemoryBankDetector = None,\n",
    "        verbose: bool = True\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Eval√∫a todas las anomal√≠as de una categor√≠a.\n",
    "        \n",
    "        Args:\n",
    "            category: Nombre de la categor√≠a\n",
    "            detector: Memory bank detector (si None, se construye uno nuevo)\n",
    "            verbose: Si True, muestra progreso\n",
    "            \n",
    "        Returns:\n",
    "            dict con m√©tricas por anomal√≠a y resumen de la categor√≠a\n",
    "        \"\"\"\n",
    "        import os\n",
    "        \n",
    "        if detector is None:\n",
    "            detector = self._build_memory_bank(category, verbose)\n",
    "        \n",
    "        anomaly_types = self._get_anomaly_types(category)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nüîç Evaluando {len(anomaly_types)} tipos de anomal√≠a en '{category}'\")\n",
    "        \n",
    "        category_results = {\n",
    "            'category': category,\n",
    "            'anomaly_results': {},\n",
    "            'all_metrics': [],\n",
    "            'summary': {}\n",
    "        }\n",
    "        \n",
    "        for anomaly_type in anomaly_types:\n",
    "            test_folder = os.path.join(self.dataset_path, category, 'test', anomaly_type)\n",
    "            gt_folder = os.path.join(self.dataset_path, category, 'ground_truth', anomaly_type)\n",
    "            \n",
    "            if not os.path.isdir(gt_folder):\n",
    "                if verbose:\n",
    "                    print(f\"  ‚ö†Ô∏è Sin ground truth para {anomaly_type}, saltando...\")\n",
    "                continue\n",
    "            \n",
    "            # Cargar pares test/ground_truth\n",
    "            test_data = load_test_with_ground_truth(\n",
    "                test_folder=test_folder,\n",
    "                gt_folder=gt_folder,\n",
    "                n_images=None  # Todas las im√°genes\n",
    "            )\n",
    "            \n",
    "            if len(test_data) == 0:\n",
    "                if verbose:\n",
    "                    print(f\"  ‚ö†Ô∏è No hay datos para {anomaly_type}\")\n",
    "                continue\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n  üìç Tipo: {anomaly_type} ({len(test_data)} im√°genes)\")\n",
    "            \n",
    "            anomaly_metrics = []\n",
    "            \n",
    "            for test_img, gt_mask, filename in test_data:\n",
    "                # Calcular mapa de anomal√≠a\n",
    "                amap, amap_smooth, score = detector.compute_anomaly_map(test_img)\n",
    "                \n",
    "                # Evaluar m√©tricas\n",
    "                metrics = self.evaluator.evaluate(amap_smooth, gt_mask)\n",
    "                metrics['filename'] = filename\n",
    "                metrics['category'] = category\n",
    "                metrics['anomaly_type'] = anomaly_type\n",
    "                metrics['image_score'] = score\n",
    "                \n",
    "                anomaly_metrics.append(metrics)\n",
    "            \n",
    "            # Calcular promedios para este tipo de anomal√≠a\n",
    "            anomaly_summary = self._compute_summary(anomaly_metrics)\n",
    "            anomaly_summary['n_images'] = len(anomaly_metrics)\n",
    "            \n",
    "            category_results['anomaly_results'][anomaly_type] = {\n",
    "                'metrics': anomaly_metrics,\n",
    "                'summary': anomaly_summary\n",
    "            }\n",
    "            category_results['all_metrics'].extend(anomaly_metrics)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"     IoU: {anomaly_summary['IoU']:.4f} | \"\n",
    "                      f\"Dice: {anomaly_summary['Dice']:.4f} | \"\n",
    "                      f\"F1: {anomaly_summary['F1']:.4f} | \"\n",
    "                      f\"AU-PRO: {anomaly_summary['AU-PRO']:.4f}\")\n",
    "        \n",
    "        # Resumen de la categor√≠a completa\n",
    "        if category_results['all_metrics']:\n",
    "            category_results['summary'] = self._compute_summary(category_results['all_metrics'])\n",
    "            category_results['summary']['n_images'] = len(category_results['all_metrics'])\n",
    "            category_results['summary']['n_anomaly_types'] = len(anomaly_types)\n",
    "        \n",
    "        return category_results\n",
    "    \n",
    "    def _compute_summary(self, metrics_list: List[dict]) -> dict:\n",
    "        \"\"\"Calcula m√©tricas promedio de una lista de m√©tricas.\"\"\"\n",
    "        if not metrics_list:\n",
    "            return {}\n",
    "        \n",
    "        summary = {}\n",
    "        metric_keys = ['IoU', 'Dice', 'Precision', 'Recall', 'F1', 'PRO', 'AU-PRO']\n",
    "        \n",
    "        for key in metric_keys:\n",
    "            values = [m[key] for m in metrics_list if key in m]\n",
    "            if values:\n",
    "                summary[key] = np.mean(values)\n",
    "                summary[f'{key}_std'] = np.std(values)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def evaluate_all(\n",
    "        self,\n",
    "        categories: List[str] = None,\n",
    "        verbose: bool = True,\n",
    "        save_results: bool = True,\n",
    "        output_path: str = None\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Eval√∫a todas las categor√≠as (o las especificadas).\n",
    "        \n",
    "        Args:\n",
    "            categories: Lista de categor√≠as a evaluar (None = todas)\n",
    "            verbose: Si True, muestra progreso detallado\n",
    "            save_results: Si True, guarda resultados en JSON\n",
    "            output_path: Ruta para guardar resultados (si save_results=True)\n",
    "            \n",
    "        Returns:\n",
    "            dict con resultados completos: por categor√≠a, por anomal√≠a y globales\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import json\n",
    "        from datetime import datetime\n",
    "        \n",
    "        if categories is None:\n",
    "            categories = self.available_categories\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üöÄ EVALUACI√ìN COMPLETA DEL DATASET MVTEC AD\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"   Modelo: {self.model_path}\")\n",
    "        print(f\"   Capa: {self.layer_idx}\")\n",
    "        print(f\"   k-NN: k={self.k}\")\n",
    "        print(f\"   Umbral: {self.threshold}\")\n",
    "        print(f\"   Categor√≠as: {len(categories)}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        all_results = {\n",
    "            'config': {\n",
    "                'model_path': self.model_path,\n",
    "                'layer_idx': self.layer_idx,\n",
    "                'k': self.k,\n",
    "                'coreset_ratio': self.coreset_ratio,\n",
    "                'threshold': self.threshold,\n",
    "                'auto_normalize': self.auto_normalize,\n",
    "                'n_good_images': self.n_good_images,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            },\n",
    "            'category_results': {},\n",
    "            'global_metrics': [],\n",
    "            'summary_by_category': {},\n",
    "            'summary_by_anomaly_type': {},\n",
    "            'global_summary': {}\n",
    "        }\n",
    "        \n",
    "        for i, category in enumerate(categories, 1):\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"üìÇ [{i}/{len(categories)}] Categor√≠a: {category.upper()}\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            try:\n",
    "                cat_results = self.evaluate_category(category, verbose=verbose)\n",
    "                all_results['category_results'][category] = cat_results\n",
    "                all_results['global_metrics'].extend(cat_results['all_metrics'])\n",
    "                all_results['summary_by_category'][category] = cat_results['summary']\n",
    "                \n",
    "                # Agregar m√©tricas por tipo de anomal√≠a al resumen global\n",
    "                for anomaly_type, anom_data in cat_results['anomaly_results'].items():\n",
    "                    key = f\"{category}/{anomaly_type}\"\n",
    "                    all_results['summary_by_anomaly_type'][key] = anom_data['summary']\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error procesando {category}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Calcular m√©tricas globales\n",
    "        if all_results['global_metrics']:\n",
    "            all_results['global_summary'] = self._compute_summary(all_results['global_metrics'])\n",
    "            all_results['global_summary']['n_total_images'] = len(all_results['global_metrics'])\n",
    "            all_results['global_summary']['n_categories'] = len(categories)\n",
    "        \n",
    "        # Imprimir resumen final\n",
    "        self._print_final_summary(all_results)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        if save_results:\n",
    "            if output_path is None:\n",
    "                output_path = os.path.join(\n",
    "                    self.dataset_path, '..', \n",
    "                    f'evaluation_results_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "                )\n",
    "            self._save_results(all_results, output_path)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def _print_final_summary(self, results: dict):\n",
    "        \"\"\"Imprime el resumen final de la evaluaci√≥n.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä RESUMEN FINAL DE EVALUACI√ìN\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Resumen por categor√≠a\n",
    "        print(\"\\nüè∑Ô∏è  M√âTRICAS POR CATEGOR√çA:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Categor√≠a':<15} {'IoU':<10} {'Dice':<10} {'F1':<10} {'Precision':<10} {'Recall':<10} {'AU-PRO':<10}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for category, summary in results['summary_by_category'].items():\n",
    "            if summary:\n",
    "                print(f\"{category:<15} \"\n",
    "                      f\"{summary.get('IoU', 0):<10.4f} \"\n",
    "                      f\"{summary.get('Dice', 0):<10.4f} \"\n",
    "                      f\"{summary.get('F1', 0):<10.4f} \"\n",
    "                      f\"{summary.get('Precision', 0):<10.4f} \"\n",
    "                      f\"{summary.get('Recall', 0):<10.4f} \"\n",
    "                      f\"{summary.get('AU-PRO', 0):<10.4f}\")\n",
    "        \n",
    "        # Resumen global\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üåç M√âTRICAS GLOBALES:\")\n",
    "        print(\"=\" * 80)\n",
    "        gs = results['global_summary']\n",
    "        if gs:\n",
    "            print(f\"   Total im√°genes evaluadas: {gs.get('n_total_images', 0)}\")\n",
    "            print(f\"   Total categor√≠as: {gs.get('n_categories', 0)}\")\n",
    "            print()\n",
    "            print(f\"   üìà M√©tricas Pixel-Level:\")\n",
    "            print(f\"      IoU:       {gs.get('IoU', 0):.4f} (¬± {gs.get('IoU_std', 0):.4f})\")\n",
    "            print(f\"      Dice:      {gs.get('Dice', 0):.4f} (¬± {gs.get('Dice_std', 0):.4f})\")\n",
    "            print(f\"      Precision: {gs.get('Precision', 0):.4f} (¬± {gs.get('Precision_std', 0):.4f})\")\n",
    "            print(f\"      Recall:    {gs.get('Recall', 0):.4f} (¬± {gs.get('Recall_std', 0):.4f})\")\n",
    "            print(f\"      F1:        {gs.get('F1', 0):.4f} (¬± {gs.get('F1_std', 0):.4f})\")\n",
    "            print()\n",
    "            print(f\"   üìà M√©tricas Region-Level:\")\n",
    "            print(f\"      PRO:       {gs.get('PRO', 0):.4f} (¬± {gs.get('PRO_std', 0):.4f})\")\n",
    "            print(f\"      AU-PRO:    {gs.get('AU-PRO', 0):.4f} (¬± {gs.get('AU-PRO_std', 0):.4f})\")\n",
    "    \n",
    "    def _save_results(self, results: dict, output_path: str):\n",
    "        \"\"\"Guarda los resultados en formato JSON.\"\"\"\n",
    "        import json\n",
    "        import os\n",
    "        \n",
    "        # Eliminar datos internos que no son serializables\n",
    "        results_clean = self._clean_results_for_json(results)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results_clean, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nüíæ Resultados guardados en: {output_path}\")\n",
    "    \n",
    "    def _clean_results_for_json(self, results: dict) -> dict:\n",
    "        \"\"\"Limpia los resultados para serializaci√≥n JSON.\"\"\"\n",
    "        import copy\n",
    "        \n",
    "        def clean_value(v):\n",
    "            if isinstance(v, (np.floating, np.integer)):\n",
    "                return float(v)\n",
    "            elif isinstance(v, np.ndarray):\n",
    "                return v.tolist()\n",
    "            elif isinstance(v, dict):\n",
    "                return {k: clean_value(val) for k, val in v.items() \n",
    "                       if not k.startswith('_')}\n",
    "            elif isinstance(v, list):\n",
    "                return [clean_value(item) for item in v]\n",
    "            else:\n",
    "                return v\n",
    "        \n",
    "        return clean_value(results)\n",
    "    \n",
    "    def generate_report(\n",
    "        self,\n",
    "        results: dict,\n",
    "        output_path: str = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Genera un reporte detallado en formato Markdown.\n",
    "        \n",
    "        Args:\n",
    "            results: Resultados de evaluate_all()\n",
    "            output_path: Ruta para guardar el reporte (opcional)\n",
    "            \n",
    "        Returns:\n",
    "            Contenido del reporte en Markdown\n",
    "        \"\"\"\n",
    "        from datetime import datetime\n",
    "        import os\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"# üìä Reporte de Evaluaci√≥n MVTec AD\")\n",
    "        report.append(f\"\\n**Fecha:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "        # Configuraci√≥n\n",
    "        config = results.get('config', {})\n",
    "        report.append(\"## ‚öôÔ∏è Configuraci√≥n\\n\")\n",
    "        report.append(f\"- **Modelo:** `{config.get('model_path', 'N/A')}`\")\n",
    "        report.append(f\"- **Capa DINOv2:** {config.get('layer_idx', 'N/A')}\")\n",
    "        report.append(f\"- **k-NN (k):** {config.get('k', 'N/A')}\")\n",
    "        report.append(f\"- **Umbral:** {config.get('threshold', 'N/A')}\")\n",
    "        report.append(f\"- **Im√°genes 'good' para Memory Bank:** {config.get('n_good_images', 'Todas')}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Resumen global\n",
    "        gs = results.get('global_summary', {})\n",
    "        report.append(\"## üåç M√©tricas Globales\\n\")\n",
    "        report.append(f\"- **Total im√°genes evaluadas:** {gs.get('n_total_images', 0)}\")\n",
    "        report.append(f\"- **Total categor√≠as:** {gs.get('n_categories', 0)}\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"| M√©trica | Valor | Desv. Est. |\")\n",
    "        report.append(\"|---------|-------|------------|\")\n",
    "        for metric in ['IoU', 'Dice', 'Precision', 'Recall', 'F1', 'PRO', 'AU-PRO']:\n",
    "            val = gs.get(metric, 0)\n",
    "            std = gs.get(f'{metric}_std', 0)\n",
    "            report.append(f\"| {metric} | {val:.4f} | ¬± {std:.4f} |\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Tabla por categor√≠a\n",
    "        report.append(\"## üè∑Ô∏è M√©tricas por Categor√≠a\\n\")\n",
    "        report.append(\"| Categor√≠a | IoU | Dice | F1 | Precision | Recall | AU-PRO |\")\n",
    "        report.append(\"|-----------|-----|------|----|-----------|----- --|--------|\")\n",
    "        \n",
    "        for category, summary in results.get('summary_by_category', {}).items():\n",
    "            if summary:\n",
    "                report.append(\n",
    "                    f\"| {category} | \"\n",
    "                    f\"{summary.get('IoU', 0):.4f} | \"\n",
    "                    f\"{summary.get('Dice', 0):.4f} | \"\n",
    "                    f\"{summary.get('F1', 0):.4f} | \"\n",
    "                    f\"{summary.get('Precision', 0):.4f} | \"\n",
    "                    f\"{summary.get('Recall', 0):.4f} | \"\n",
    "                    f\"{summary.get('AU-PRO', 0):.4f} |\"\n",
    "                )\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # Detalle por tipo de anomal√≠a\n",
    "        report.append(\"## üî¨ Detalle por Tipo de Anomal√≠a\\n\")\n",
    "        \n",
    "        for category, cat_data in results.get('category_results', {}).items():\n",
    "            report.append(f\"### {category.upper()}\\n\")\n",
    "            report.append(\"| Tipo de Anomal√≠a | Im√°genes | IoU | Dice | F1 | AU-PRO |\")\n",
    "            report.append(\"|------------------|----------|-----|------|----|----- --|\")\n",
    "            \n",
    "            for anomaly_type, anom_data in cat_data.get('anomaly_results', {}).items():\n",
    "                summary = anom_data.get('summary', {})\n",
    "                report.append(\n",
    "                    f\"| {anomaly_type} | \"\n",
    "                    f\"{summary.get('n_images', 0)} | \"\n",
    "                    f\"{summary.get('IoU', 0):.4f} | \"\n",
    "                    f\"{summary.get('Dice', 0):.4f} | \"\n",
    "                    f\"{summary.get('F1', 0):.4f} | \"\n",
    "                    f\"{summary.get('AU-PRO', 0):.4f} |\"\n",
    "                )\n",
    "            report.append(\"\")\n",
    "        \n",
    "        report_content = \"\\n\".join(report)\n",
    "        \n",
    "        # Guardar si se especifica ruta\n",
    "        if output_path:\n",
    "            os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(report_content)\n",
    "            print(f\"\\nüìù Reporte guardado en: {output_path}\")\n",
    "        \n",
    "        return report_content\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    print(\"=\" * 80)\n",
    "    print(\"üöÄ EVALUACI√ìN COMPLETA DEL DATASET MVTEC AD\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Crear evaluador\n",
    "    evaluator_mvtec = MVTecDatasetEvaluator(\n",
    "        dataset_path=\"/home/bllancao/Portafolio/mvtec_anomaly_detection/data/raw\",\n",
    "        model_path=\"/home/bllancao/Portafolio/mvtec_anomaly_detection/models/dinov2-base\",\n",
    "        layer_idx=-1,\n",
    "        n_good_images=200,\n",
    "        k=1,\n",
    "        threshold=0.6\n",
    "    )\n",
    "    \n",
    "    # Evaluar todas las categor√≠as (o las especificadas)\n",
    "    results = evaluator_mvtec.evaluate_all(\n",
    "        categories=[\"bottle\", \"cable\", \"capsule\", \"carpet\", \"grid\", \"hazelnut\", \"leather\", \"metal_nut\", \"pill\", \"screw\", \"tile\", \"toothbrush\", \"transistor\", \"wood\", \"zipper\"],\n",
    "        verbose=True,\n",
    "        save_results=False,\n",
    "        output_path=None\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Evaluaci√≥n completa finalizada\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch271",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
